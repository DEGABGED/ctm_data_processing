{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "from ctmmodels.const import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "currdir = os.getcwd()\n",
    "regex_name = r'(([A-Z])\\w+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS FOR EACH PROCESSING\n",
    "\n",
    "IMAGE_PATH = 'graphs/experiments-5/'\n",
    "DF_PATH = 'experiments-final5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY_ZONE_MAPPING = {'30': (2, 2, 0), '22': (3, 1, 2), '2c': (2, 0, 0), '28': (2, 2, 1), '25': (3, 2, 1), '26': (3, 1, 1), '27': (3, 0, 1), '20': (2, 2, 2), '21': (3, 2, 2), '1e': (3, 1, 2), '23': (3, 0, 2), '24': (2, 0, 1), '29': (3, 2, 1), '1a': (3, 1, 3), '0': (1, 0, 3), '3': (3, 1, 0), '2': (3, 2, 0), '5': (1, 0, 0), '1d': (3, 2, 2), '7': (2, 1, 1), '1f': (3, 0, 2), '9': (3, 1, 1), '8': (3, 2, 1), '3a': (3, 1, 3), '1c': (2, 0, 2), '4': (3, 0, 0), 'a': (3, 0, 1), '6': (1, 0, 1), '39': (3, 2, 3), '12': (1, 0, 2), '3b': (3, 0, 3), '1b': (3, 0, 3), 'b': (1, 0, 2), '13': (1, 0, 2), 'd': (3, 2, 2), '11': (1, 0, 3), '10': (1, 0, 3), 'c': (2, 1, 2), '38': (2, 0, 3), '15': (1, 0, 1), '14': (1, 0, 1), '17': (1, 0, 0), 'f': (3, 0, 2), '19': (3, 2, 3), '32': (3, 1, 0), '31': (3, 2, 0), '16': (1, 0, 0), '37': (3, 0, 3), '36': (3, 1, 3), '35': (3, 2, 3), '34': (2, 1, 3), '2d': (3, 2, 0), '2e': (3, 1, 0), '2f': (3, 0, 0), '1': (2, 1, 0), '2a': (3, 1, 1), '2b': (3, 0, 1), '18': (2, 2, 3), '33': (3, 0, 0), 'e': (3, 1, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_approach = SOUTHBOUND\n",
    "\n",
    "_approach_terms = [\n",
    "    'Left',\n",
    "    'Through',\n",
    "    'Right'\n",
    "]\n",
    "\n",
    "_cell_path = [\n",
    "    (CELL_SOURCE,0,_approach),\n",
    "    (CELL_NORMAL,0,_approach),\n",
    "    (CELL_NORMAL,1,_approach),\n",
    "    (CELL_NORMAL,2,_approach),\n",
    "    (CELL_MOVEMENT,THROUGH_TURN,_approach),\n",
    "    S_mapping((CELL_MOVEMENT,THROUGH_TURN,_approach))[0]\n",
    "]\n",
    "\n",
    "_movement_labels = {\n",
    "    (2,LEFT_TURN,NORTHBOUND): 'NBL',\n",
    "    (2,RIGHT_TURN,NORTHBOUND): 'NBR',\n",
    "    (2,THROUGH_TURN,NORTHBOUND): 'NBT',\n",
    "    (2,LEFT_TURN,SOUTHBOUND): 'SBL',\n",
    "    (2,RIGHT_TURN,SOUTHBOUND): 'SBR',\n",
    "    (2,THROUGH_TURN,SOUTHBOUND): 'SBT',\n",
    "    (2,LEFT_TURN,EASTBOUND): 'EBL',\n",
    "    (2,RIGHT_TURN,EASTBOUND): 'EBR',\n",
    "    (2,THROUGH_TURN,EASTBOUND): 'EBT',\n",
    "    (2,LEFT_TURN,WESTBOUND): 'WBL',\n",
    "    (2,RIGHT_TURN,WESTBOUND): 'WBR',\n",
    "    (2,THROUGH_TURN,WESTBOUND): 'WBT',\n",
    "}\n",
    "\n",
    "_demands = [\n",
    "    450,\n",
    "    900,\n",
    "    (450, 900),\n",
    "    (900, 1800)\n",
    "]\n",
    "\n",
    "_weights = [\n",
    "    (1, 0, 0),\n",
    "    (0, 1, 0),\n",
    "    (0, 0, 1),\n",
    "    (0.5, 0.5, 0),\n",
    "    (0, 0.5, 0.5),\n",
    "    (0.5, 0, 0.5),\n",
    "    (0.33, 0.33, 0.33),\n",
    "    (0, 0, 0)\n",
    "]\n",
    "\n",
    "_model_type = {\n",
    "    (1, 0, 0): 'Delay priority',\n",
    "    (0, 1, 0): 'Throughput priority',\n",
    "    (0, 0, 1): 'Flow priority',\n",
    "    (0.5, 0.5, 0): 'Delay-Throughput priority',\n",
    "    (0, 0.5, 0.5): 'Throughput-Flow priority',\n",
    "    (0.5, 0, 0.5): 'Delay-Flow priority',\n",
    "    (0.33, 0.33, 0.33): 'Equal priority',\n",
    "    (0, 0, 0): 'Parent model',\n",
    "}\n",
    "\n",
    "_col_rename = {\n",
    "    'Runtime': 'runtime',\n",
    "    'Delay': 'delay',\n",
    "    'Throughput': 'throughput',\n",
    "    'ObjValue': 'objective_value',\n",
    "    'Average time': 'travel_time',\n",
    "    'Average speed': 'average_speed',\n",
    "}\n",
    "\n",
    "ROUTE_MAPPING = {\n",
    "    'approach0_lane1-North_to_East-exit1_lane1': ('North', 'Left'),\n",
    "    'approach0_lane2-North_to_South_Lane2_Lane3-exit2_lane2': ('North', 'Through'),\n",
    "    'approach0_lane3-North_to_West-exit3_lane3': ('North', 'Right'),\n",
    "    'approach1_lane1-East_to_South-exit2_lane1': ('East', 'Left'),\n",
    "    'approach1_lane2-East_to_West_Lane2_Lane3-exit3_lane2': ('East', 'Through'),\n",
    "    'approach1_lane3-East_to_North-exit0_lane3': ('East', 'Right'),\n",
    "    'approach2_lane1-South_to_West-exit3_lane1': ('South', 'Left'),\n",
    "    'approach2_lane2-South_to_North_Lane2_Lane3-exit0_lane2': ('South', 'Through'),\n",
    "    'approach2_lane3-South_to_East-exit1_lane3': ('South', 'Right'),\n",
    "    'approach3_lane1-West_to_North-exit0_lane1': ('West', 'Left'),\n",
    "    'approach3_lane2-West_to_East_Lane2_Lane3-exit1_lane2': ('West', 'Through'),\n",
    "    'approach3_lane3-West_to_South-exit2_lane3': ('West', 'Right')\n",
    "}\n",
    "\n",
    "def movement_paths(approach):\n",
    "    return [\n",
    "        [\n",
    "            (CELL_SOURCE,0,approach),\n",
    "            (CELL_NORMAL,0,approach),\n",
    "            (CELL_NORMAL,1,approach),\n",
    "            (CELL_NORMAL,2,approach),\n",
    "            (CELL_MOVEMENT,LEFT_TURN,approach),\n",
    "            S_mapping((CELL_MOVEMENT,LEFT_TURN,approach))[0]\n",
    "        ],\n",
    "        [\n",
    "            (CELL_SOURCE,0,approach),\n",
    "            (CELL_NORMAL,0,approach),\n",
    "            (CELL_NORMAL,1,approach),\n",
    "            (CELL_NORMAL,2,approach),\n",
    "            (CELL_MOVEMENT,THROUGH_TURN,approach),\n",
    "            S_mapping((CELL_MOVEMENT,THROUGH_TURN,approach))[0]\n",
    "        ],\n",
    "        [\n",
    "            (CELL_SOURCE,0,approach),\n",
    "            (CELL_NORMAL,0,approach),\n",
    "            (CELL_NORMAL,1,approach),\n",
    "            (CELL_NORMAL,2,approach),\n",
    "            (CELL_MOVEMENT,RIGHT_TURN,approach),\n",
    "            S_mapping((CELL_MOVEMENT,RIGHT_TURN,approach))[0]\n",
    "        ]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments Results Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = currdir + '/{}sim-results/result_d450_a0.5_b0.5_c0.xls'.format(DF_PATH)\n",
    "df_tmp = pd.read_excel(filename, sheet_name='Speed').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>0x22 - approach2_lane3</th>\n",
       "      <th>0x20 - approach2_lane3</th>\n",
       "      <th>0x7 - approach1_lane2</th>\n",
       "      <th>0x25 - approach1_lane1</th>\n",
       "      <th>0x19 - approach3_lane3</th>\n",
       "      <th>0x32 - approach0_lane3</th>\n",
       "      <th>0x31 - approach0_lane3</th>\n",
       "      <th>0x28 - approach1_lane3</th>\n",
       "      <th>0x17 - exit0_lane1</th>\n",
       "      <th>...</th>\n",
       "      <th>0x27 - approach1_lane1</th>\n",
       "      <th>0x15 - exit1_lane1</th>\n",
       "      <th>0x10 - exit3_lane3</th>\n",
       "      <th>0x12 - exit2_lane3</th>\n",
       "      <th>0x13 - exit2_lane1</th>\n",
       "      <th>0x14 - exit1_lane3</th>\n",
       "      <th>0x2e - approach0_lane1</th>\n",
       "      <th>0xc - approach2_lane2</th>\n",
       "      <th>0xb - exit2_lane2</th>\n",
       "      <th>0x18 - approach3_lane3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>73.844426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.612968</td>\n",
       "      <td>13.767763</td>\n",
       "      <td>88.992000</td>\n",
       "      <td>67.113730</td>\n",
       "      <td>74.125612</td>\n",
       "      <td>85.472000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.215519</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>75.816000</td>\n",
       "      <td>90.720000</td>\n",
       "      <td>82.080000</td>\n",
       "      <td>95.488000</td>\n",
       "      <td>43.598769</td>\n",
       "      <td>11.840977</td>\n",
       "      <td>63.360000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>74.160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.283647</td>\n",
       "      <td>10.480865</td>\n",
       "      <td>70.419757</td>\n",
       "      <td>69.794308</td>\n",
       "      <td>78.897913</td>\n",
       "      <td>85.472000</td>\n",
       "      <td>55.296000</td>\n",
       "      <td>...</td>\n",
       "      <td>33.871385</td>\n",
       "      <td>54.889412</td>\n",
       "      <td>82.080000</td>\n",
       "      <td>79.380000</td>\n",
       "      <td>67.156364</td>\n",
       "      <td>89.520000</td>\n",
       "      <td>41.984000</td>\n",
       "      <td>10.708260</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180</td>\n",
       "      <td>75.123117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935624</td>\n",
       "      <td>11.469904</td>\n",
       "      <td>73.956822</td>\n",
       "      <td>67.779871</td>\n",
       "      <td>76.872293</td>\n",
       "      <td>88.759385</td>\n",
       "      <td>55.542857</td>\n",
       "      <td>...</td>\n",
       "      <td>31.358671</td>\n",
       "      <td>53.760000</td>\n",
       "      <td>83.676522</td>\n",
       "      <td>81.648000</td>\n",
       "      <td>62.537143</td>\n",
       "      <td>94.785882</td>\n",
       "      <td>36.906865</td>\n",
       "      <td>8.057106</td>\n",
       "      <td>61.714286</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>75.749143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.927978</td>\n",
       "      <td>8.417641</td>\n",
       "      <td>73.105592</td>\n",
       "      <td>68.345174</td>\n",
       "      <td>78.417095</td>\n",
       "      <td>88.759385</td>\n",
       "      <td>59.616000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.493611</td>\n",
       "      <td>54.720000</td>\n",
       "      <td>85.236923</td>\n",
       "      <td>82.472727</td>\n",
       "      <td>59.694545</td>\n",
       "      <td>93.996000</td>\n",
       "      <td>33.529884</td>\n",
       "      <td>6.502334</td>\n",
       "      <td>60.480000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>76.000467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.864363</td>\n",
       "      <td>6.701683</td>\n",
       "      <td>73.773078</td>\n",
       "      <td>68.864137</td>\n",
       "      <td>79.432396</td>\n",
       "      <td>88.759385</td>\n",
       "      <td>57.202759</td>\n",
       "      <td>...</td>\n",
       "      <td>13.562124</td>\n",
       "      <td>54.093913</td>\n",
       "      <td>85.945263</td>\n",
       "      <td>81.270000</td>\n",
       "      <td>59.694545</td>\n",
       "      <td>95.914286</td>\n",
       "      <td>30.034708</td>\n",
       "      <td>5.408193</td>\n",
       "      <td>60.480000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t  0x22 - approach2_lane3  0x20 - approach2_lane3  0x7 - approach1_lane2  \\\n",
       "0   60               73.844426                     0.0               7.612968   \n",
       "1  120               74.160000                     0.0               8.283647   \n",
       "2  180               75.123117                     0.0               7.935624   \n",
       "3  240               75.749143                     0.0               7.927978   \n",
       "4  300               76.000467                     0.0               8.864363   \n",
       "\n",
       "   0x25 - approach1_lane1  0x19 - approach3_lane3  0x32 - approach0_lane3  \\\n",
       "0               13.767763               88.992000               67.113730   \n",
       "1               10.480865               70.419757               69.794308   \n",
       "2               11.469904               73.956822               67.779871   \n",
       "3                8.417641               73.105592               68.345174   \n",
       "4                6.701683               73.773078               68.864137   \n",
       "\n",
       "   0x31 - approach0_lane3  0x28 - approach1_lane3  0x17 - exit0_lane1  ...  \\\n",
       "0               74.125612               85.472000            0.000000  ...   \n",
       "1               78.897913               85.472000           55.296000  ...   \n",
       "2               76.872293               88.759385           55.542857  ...   \n",
       "3               78.417095               88.759385           59.616000  ...   \n",
       "4               79.432396               88.759385           57.202759  ...   \n",
       "\n",
       "   0x27 - approach1_lane1  0x15 - exit1_lane1  0x10 - exit3_lane3  \\\n",
       "0               31.215519           51.840000           75.816000   \n",
       "1               33.871385           54.889412           82.080000   \n",
       "2               31.358671           53.760000           83.676522   \n",
       "3               20.493611           54.720000           85.236923   \n",
       "4               13.562124           54.093913           85.945263   \n",
       "\n",
       "   0x12 - exit2_lane3  0x13 - exit2_lane1  0x14 - exit1_lane3  \\\n",
       "0           90.720000           82.080000           95.488000   \n",
       "1           79.380000           67.156364           89.520000   \n",
       "2           81.648000           62.537143           94.785882   \n",
       "3           82.472727           59.694545           93.996000   \n",
       "4           81.270000           59.694545           95.914286   \n",
       "\n",
       "   0x2e - approach0_lane1  0xc - approach2_lane2  0xb - exit2_lane2  \\\n",
       "0               43.598769              11.840977          63.360000   \n",
       "1               41.984000              10.708260          67.200000   \n",
       "2               36.906865               8.057106          61.714286   \n",
       "3               33.529884               6.502334          60.480000   \n",
       "4               30.034708               5.408193          60.480000   \n",
       "\n",
       "   0x18 - approach3_lane3  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out some of the rows\n",
    "\n",
    "delay_rows = [\"{} Delay\".format(d) for d in range(60,601,60)]\n",
    "delay_rename = dict([\n",
    "    (\"{} Delay\".format(d), d)\n",
    "    for d in range(60,601,60)\n",
    "])\n",
    "\n",
    "thru_rows = [\"{} Throughput\".format(d) for d in range(60,601,60)]\n",
    "thru_rename = dict([\n",
    "    (\"{} Throughput\".format(d), d)\n",
    "    for d in range(60,601,60)\n",
    "])\n",
    "\n",
    "vol_rows = [d for d in range(60,601,60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 approach zones, 12 exit zones\n"
     ]
    }
   ],
   "source": [
    "# Filter out some of the columns\n",
    "\n",
    "survey_zones = df_tmp.columns.values[1:]\n",
    "\n",
    "entrances = [x for x in survey_zones if 'approach' in x]\n",
    "exits = [y for y in survey_zones if 'exit' in y]\n",
    "\n",
    "print(\"{} approach zones, {} exit zones\".format(len(entrances), len(exits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_approach = re.compile('0x(\\w+) - approach.*')\n",
    "reg_exit = re.compile('0x(\\w+) - exit.*')\n",
    "\n",
    "entrances_rename = dict([\n",
    "    (k, SURVEY_ZONE_MAPPING[reg_approach.match(k).group(1)])\n",
    "    for k in entrances\n",
    "])\n",
    "\n",
    "exits_rename = dict([\n",
    "    (k, SURVEY_ZONE_MAPPING[reg_exit.match(k).group(1)])\n",
    "    for k in exits\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_thru_dfs = []\n",
    "total_delay_dfs = []\n",
    "ave_delay_dfs = []\n",
    "ave_speed_dfs = []\n",
    "ave_travel_time_dfs = []\n",
    "\n",
    "for demand in _demands:\n",
    "    for weights in _weights:\n",
    "\n",
    "        partial_fn = 'old' if weights == (0, 0, 0) else 'a{}_b{}_c{}'.format(*weights)\n",
    "        filename = currdir + '/{}sim-results/result_d{}_{}.xls'.format(DF_PATH, demand, partial_fn)\n",
    "\n",
    "        # Get volumes\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='Volume').fillna(0)\n",
    "\n",
    "        df_tmp1 = df_tmp[df_tmp.t.isin(vol_rows)]\n",
    "        df_tmp1 = df_tmp1.sort_values(by='t').set_index('t')[entrances].stack().reset_index()\n",
    "        df_tmp1['level_1'] = df_tmp1['level_1'].map(entrances_rename)\n",
    "        df_tmp1 = df_tmp1.groupby(['t', 'level_1']).sum().reset_index()\n",
    "\n",
    "        df_volume = df_tmp1.pivot(index='t', columns='level_1', values=0)\n",
    "        df_volume.to_pickle(currdir + '/{}actual-volume/vol_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "        \n",
    "        # Get CVCC\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='CVCC').fillna(0).set_index('t')\n",
    "\n",
    "        df_cvcc = df_tmp.rename(columns=entrances_rename).rename(columns=exits_rename)\n",
    "        df_cvcc = df_cvcc.stack().reset_index().pivot_table(index='t', columns='level_1', values=0, aggfunc='sum')\n",
    "        \n",
    "        df_cvcc.to_pickle(currdir + '/{}cvcc/cvcc_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "        \n",
    "        # Get Travel Time\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='Travel time (s)')\n",
    "\n",
    "        df_tmp['approach'] = df_tmp.apply(lambda row: ROUTE_MAPPING[row['Route']][0], axis=1)\n",
    "        df_tmp['movement'] = df_tmp.apply(lambda row: ROUTE_MAPPING[row['Route']][1], axis=1)\n",
    "        df_tmp = df_tmp[['Average time', 'approach', 'movement']].rename(columns=_col_rename)\n",
    "        df_tmp['demand'] = [demand] * df_tmp.shape[0]\n",
    "        df_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_tmp['alpha'] = weights[0]\n",
    "        df_tmp['beta'] = weights[1]\n",
    "        df_tmp['gamma'] = weights[2]\n",
    "        df_tmp['model_type'] = _model_type[weights]\n",
    "        ave_travel_time_dfs.append(df_tmp)\n",
    "        \n",
    "        # Get Average Speed\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='Travel speed (kph)')\n",
    "\n",
    "        df_tmp['approach'] = df_tmp.apply(lambda row: ROUTE_MAPPING[row['Route']][0], axis=1)\n",
    "        df_tmp['movement'] = df_tmp.apply(lambda row: ROUTE_MAPPING[row['Route']][1], axis=1)\n",
    "        df_tmp = df_tmp[['Average speed', 'approach', 'movement']].rename(columns=_col_rename)\n",
    "        df_tmp['demand'] = [demand] * df_tmp.shape[0]\n",
    "        df_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_tmp['alpha'] = weights[0]\n",
    "        df_tmp['beta'] = weights[1]\n",
    "        df_tmp['gamma'] = weights[2]\n",
    "        df_tmp['model_type'] = _model_type[weights]\n",
    "        ave_speed_dfs.append(df_tmp)\n",
    "\n",
    "        # Get the cumulative delays\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='Speed').fillna(0)\n",
    "\n",
    "        df_tmp1 = df_tmp[df_tmp.t.isin(delay_rows)]\n",
    "        df_tmp1['t'].replace(delay_rename, inplace=True)\n",
    "        df_tmp1 = df_tmp1.sort_values(by='t').set_index('t')[entrances].stack().reset_index()\n",
    "        df_tmp1['level_1'] = df_tmp1['level_1'].map(entrances_rename)\n",
    "        df_tmp1 = df_tmp1.groupby(['t', 'level_1']).sum().reset_index()\n",
    "\n",
    "        df_cumdelay = df_tmp1.pivot(index='t', columns='level_1', values=0)\n",
    "        df_cumdelay.to_pickle(currdir + '/{}cumu-delay/delay_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "        \n",
    "        # Get the cumulative throughputs\n",
    "\n",
    "        df_tmp3 = df_tmp[df_tmp.t.isin(thru_rows)]\n",
    "#         if weights == (0, 0, 0):\n",
    "#             for col in ['0x11 - exit3_lane1', '0x15 - exit1_lane1', '0x17 - exit0_lane1', '0x13 - exit2_lane1']:\n",
    "#                 if col not in df_tmp3.columns:\n",
    "#                     df_tmp3[col] = 0\n",
    "        df_tmp3['t'].replace(thru_rename, inplace=True)\n",
    "        df_tmp3 = df_tmp3.sort_values(by='t').set_index('t')[exits].stack().reset_index()\n",
    "        df_tmp3['level_1'] = df_tmp3['level_1'].map(exits_rename)\n",
    "        df_tmp3 = df_tmp3.groupby(['t', 'level_1']).sum().reset_index()\n",
    "\n",
    "        df_cumthru = df_tmp3.pivot(index='t', columns='level_1', values=0)\n",
    "        df_cumthru.to_pickle(currdir + '/{}cumu-thru/thru_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "\n",
    "        # Get aggregate values\n",
    "\n",
    "        df_total_thru_tmp = df_cumthru.loc[600, :].reset_index().set_index('level_1').T\n",
    "        df_total_thru_tmp['demand'] = [demand]\n",
    "        df_total_thru_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_total_thru_tmp['alpha'] = weights[0]\n",
    "        df_total_thru_tmp['beta'] = weights[1]\n",
    "        df_total_thru_tmp['gamma'] = weights[2]\n",
    "        df_total_thru_tmp['model_type'] = _model_type[weights]\n",
    "        total_thru_dfs.append(df_total_thru_tmp)\n",
    "\n",
    "        df_total_delay_tmp = df_cumdelay.loc[600, :].reset_index().set_index('level_1').T\n",
    "        df_total_delay_tmp['demand'] = [demand]\n",
    "        df_total_delay_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_total_delay_tmp['alpha'] = weights[0]\n",
    "        df_total_delay_tmp['beta'] = weights[1]\n",
    "        df_total_delay_tmp['gamma'] = weights[2]\n",
    "        df_total_delay_tmp['model_type'] = _model_type[weights]\n",
    "        total_delay_dfs.append(df_total_delay_tmp)\n",
    "\n",
    "        df_tmp2 = df_tmp[df_tmp.t == 'Average Delay'][entrances].rename(columns=entrances_rename).stack().reset_index()\n",
    "        df_ave_delay_tmp = df_tmp2.groupby('level_1').mean().reset_index().pivot(index='level_0', columns='level_1', values=0)\n",
    "        df_ave_delay_tmp['demand'] = [demand]\n",
    "        df_ave_delay_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_ave_delay_tmp['alpha'] = weights[0]\n",
    "        df_ave_delay_tmp['beta'] = weights[1]\n",
    "        df_ave_delay_tmp['gamma'] = weights[2]\n",
    "        df_ave_delay_tmp['model_type'] = _model_type[weights]\n",
    "        ave_delay_dfs.append(df_ave_delay_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_thru = pd.concat(total_thru_dfs).reset_index().iloc[:, 1:]\n",
    "df_total_thru.to_pickle(currdir + '/{}total_throughput.pkl'.format(DF_PATH))\n",
    "\n",
    "df_total_delay = pd.concat(total_delay_dfs).reset_index().iloc[:, 1:]\n",
    "df_total_delay.to_pickle(currdir + '/{}total_delay.pkl'.format(DF_PATH))\n",
    "\n",
    "df_ave_delay = pd.concat(ave_delay_dfs).reset_index().iloc[:, 1:]\n",
    "df_ave_delay.to_pickle(currdir + '/{}ave_delay.pkl'.format(DF_PATH))\n",
    "\n",
    "df_ave_speed = pd.concat(ave_speed_dfs).reset_index().iloc[:, 1:]\n",
    "df_ave_speed.to_pickle(currdir + '/{}ave_speed.pkl'.format(DF_PATH))\n",
    "\n",
    "df_travel_time = pd.concat(ave_travel_time_dfs).reset_index().iloc[:, 1:]\n",
    "df_travel_time.to_pickle(currdir + '/{}ave_travel_time.pkl'.format(DF_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greentimes from Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing greentimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_greentime_map(dfg, title=\"Greentime maps\", headless=False, filename='greentime.png', movements=True):\n",
    "    fig, axs = plt.subplots(figsize=(10,5))\n",
    "\n",
    "    dfg_matrix = dfg.T\n",
    "    if movements:\n",
    "        dfg_matrix = dfg_matrix.reindex(index=[\n",
    "            (2,LEFT_TURN,NORTHBOUND), (2,RIGHT_TURN,NORTHBOUND), (2,THROUGH_TURN,NORTHBOUND),\n",
    "            (2,LEFT_TURN,SOUTHBOUND), (2,RIGHT_TURN,SOUTHBOUND), (2,THROUGH_TURN,SOUTHBOUND),\n",
    "            (2,LEFT_TURN,EASTBOUND), (2,RIGHT_TURN,EASTBOUND), (2,THROUGH_TURN,EASTBOUND),\n",
    "            (2,LEFT_TURN,WESTBOUND), (2,RIGHT_TURN,WESTBOUND), (2,THROUGH_TURN,WESTBOUND),\n",
    "        ]).rename(index=_movement_labels).rename_axis(index='Movements', columns='Timesteps')\n",
    "    sns.heatmap(data=dfg_matrix, cbar=False)\n",
    "    \n",
    "    fig.suptitle(title, fontsize=18)\n",
    "    \n",
    "    if headless:\n",
    "        fig.savefig(IMAGE_PATH + filename)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, filename):\n",
    "    df.to_pickle(DF_PATH + filename + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_demands = [\n",
    "    450,\n",
    "    900,\n",
    "    (450, 900),\n",
    "    (900, 1800)\n",
    "]\n",
    "\n",
    "_weights = [\n",
    "    (1, 0, 0),\n",
    "    (0, 1, 0),\n",
    "    (0, 0, 1),\n",
    "    (0.5, 0.5, 0),\n",
    "    (0, 0.5, 0.5),\n",
    "    (0.5, 0, 0.5),\n",
    "    (0.33, 0.33, 0.33),\n",
    "    (0, 0, 0)\n",
    "]\n",
    "\n",
    "for demand in _demands:\n",
    "    for weights in _weights:\n",
    "        if weights == (0,0,0):\n",
    "            df_e0 = pd.read_pickle(DF_PATH + 'greentimes/initial/greentimes_d{}_old.pkl'.format(demand))\n",
    "            df_e1 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch1_old.pkl'.format(demand))\n",
    "            df_e2 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch2_old.pkl'.format(demand))\n",
    "            df_e3 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch3_old.pkl'.format(demand))\n",
    "            subtitle = 'Old model'\n",
    "            filename = 'old'\n",
    "        else:\n",
    "            df_e0 = pd.read_pickle(DF_PATH + 'greentimes/initial/greentimes_d{}_new_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "            df_e1 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch1_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "            df_e2 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch2_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "            df_e3 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch3_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "            subtitle = 'New model ({})'.format(_model_type[weights])\n",
    "            filename = 'a{}_b{}_c{}'.format(*weights)\n",
    "            \n",
    "        plot_greentime_map(\n",
    "            df_e0,\n",
    "            title='Greentimes for demand {} and {} (Initial)'.format(demand, subtitle),\n",
    "            headless=True,\n",
    "            filename='d{}_{}_epoch0.png'.format(demand, filename)\n",
    "        )\n",
    "\n",
    "        plot_greentime_map(\n",
    "            df_e1,\n",
    "            title='Greentimes for demand {} and {} (Epoch 1)'.format(demand, subtitle),\n",
    "            headless=True,\n",
    "            filename='d{}_{}_epoch1.png'.format(demand, filename)\n",
    "        )\n",
    "        \n",
    "        plot_greentime_map(\n",
    "            df_e2,\n",
    "            title='Greentimes for demand {} and {} (Epoch 2)'.format(demand, subtitle),\n",
    "            headless=True,\n",
    "            filename='d{}_{}_epoch2.png'.format(demand, filename)\n",
    "        )\n",
    "        \n",
    "        plot_greentime_map(\n",
    "            df_e3,\n",
    "            title='Greentimes for demand {} and {} (Epoch 3)'.format(demand, subtitle),\n",
    "            headless=True,\n",
    "            filename='d{}_{}_epoch3.png'.format(demand, filename)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results from MILP Realtime Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining across epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results_dflist = []\n",
    "\n",
    "for demand in _demands:\n",
    "    for weights in _weights:\n",
    "        if weights == (0,0,0):\n",
    "            df_e1 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch1_old.csv'.format(demand))\n",
    "            df_e2 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch2_old.csv'.format(demand))\n",
    "            df_e3 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch3_old.csv'.format(demand))\n",
    "        else:\n",
    "            df_e1 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch1_a{}_b{}_c{}.csv'.format(demand, *weights))\n",
    "            df_e2 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch2_a{}_b{}_c{}.csv'.format(demand, *weights))\n",
    "            df_e3 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch3_a{}_b{}_c{}.csv'.format(demand, *weights))\n",
    "\n",
    "        df_e1 = df_e1.rename(columns=_col_rename)\n",
    "        df_e1['demand'] = [demand]\n",
    "        df_e1['new_model'] = weights != (0,0,0)\n",
    "        df_e1['alpha'] = weights[0]\n",
    "        df_e1['beta'] = weights[1]\n",
    "        df_e1['gamma'] = weights[2]\n",
    "        df_e1['model_type'] = _model_type[weights]\n",
    "        df_e1['epoch'] = 1\n",
    "        \n",
    "        df_e2 = df_e2.rename(columns=_col_rename)\n",
    "        df_e2['demand'] = [demand]\n",
    "        df_e2['new_model'] = weights != (0,0,0)\n",
    "        df_e2['alpha'] = weights[0]\n",
    "        df_e2['beta'] = weights[1]\n",
    "        df_e2['gamma'] = weights[2]\n",
    "        df_e2['model_type'] = _model_type[weights]\n",
    "        df_e2['epoch'] = 2\n",
    "        \n",
    "        df_e3 = df_e3.rename(columns=_col_rename)\n",
    "        df_e3['demand'] = [demand]\n",
    "        df_e3['new_model'] = weights != (0,0,0)\n",
    "        df_e3['alpha'] = weights[0]\n",
    "        df_e3['beta'] = weights[1]\n",
    "        df_e3['gamma'] = weights[2]\n",
    "        df_e3['model_type'] = _model_type[weights]\n",
    "        df_e3['epoch'] = 3\n",
    "        \n",
    "        _results_dflist.append(pd.concat([df_e1, df_e2, df_e3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(_results_dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_results = pd.read_pickle(DF_PATH + 'results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_results['demand'] = df_initial_results.apply(lambda row: \n",
    "                                                        int(row['demand_ns']) if row['demand_ns'] == row['demand_ew']\n",
    "                                                        else (int(row['demand_ns']), int(row['demand_ew']))\n",
    "                                                        , axis=1)\n",
    "\n",
    "df_initial_results['new_model'] = df_initial_results.apply(lambda row: row['alpha'] != 0, axis=1)\n",
    "\n",
    "df_initial_results['model_type'] = df_initial_results.apply(lambda row: _model_type[\n",
    "    (row['alpha'], row['beta'], row['gamma'])\n",
    "], axis=1)\n",
    "\n",
    "df_initial_results['epoch'] = 0\n",
    "\n",
    "df_initial_results['delay'] = df_initial_results['delay'].apply(lambda x: 2*x)\n",
    "\n",
    "df_initial_results = df_initial_results[[\n",
    "    'runtime',\n",
    "    'delay',\n",
    "    'throughput',\n",
    "    'objective_value',\n",
    "    'demand',\n",
    "    'new_model',\n",
    "    'alpha',\n",
    "    'beta',\n",
    "    'gamma',\n",
    "    'model_type',\n",
    "    'epoch'\n",
    "]]\n",
    "\n",
    "df = df.rename(columns={'obj-value': 'objective_value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_initial_results, df]).sort_values(by=['epoch', 'demand', 'model_type'])\n",
    "\n",
    "save_df(df_final, 'milp-realtime-results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected vs Actual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_dfs = []\n",
    "throughput_dfs = []\n",
    "\n",
    "df_milp = pd.read_pickle(DF_PATH + 'milp-realtime-results.pkl')\n",
    "df_delay = pd.DataFrame(columns=['demand', 'model_type', 'expected', 'actual', 'epoch'])\n",
    "df_thru = pd.DataFrame(columns=['demand', 'model_type', 'expected', 'actual', 'epoch'])\n",
    "\n",
    "for demand in _demands:\n",
    "    for weights in _weights:\n",
    "\n",
    "        # Get actual values\n",
    "        \n",
    "        df_cumdelay_tmp = pd.read_pickle(DF_PATH + 'cumu-delay/delay_d{}_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "        df_instdelay_tmp = df_cumdelay_tmp.diff()\n",
    "        df_instdelay_tmp.loc[60, :] = df_cumdelay_tmp.loc[60, :]\n",
    "        actual_delay = list(df_instdelay_tmp.sum(axis=1)[[60, 240, 420]])\n",
    "        \n",
    "        df_cumthru_tmp = pd.read_pickle(DF_PATH + 'cumu-thru/thru_d{}_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "        df_instthru_tmp = df_cumthru_tmp.diff()\n",
    "        df_instthru_tmp.loc[60, :] = df_cumthru_tmp.loc[60, :]\n",
    "        actual_thru = list(df_instthru_tmp.sum(axis=1)[[60, 240, 420]])\n",
    "\n",
    "        # Get expected values\n",
    "        \n",
    "        expected_delay = list(df_milp[(df_milp.demand == demand) & (df_milp.model_type == _model_type[weights])].delay)\n",
    "        expected_thru = list(df_milp[(df_milp.demand == demand) & (df_milp.model_type == _model_type[weights])].throughput)\n",
    "        \n",
    "        # Combine into a dataframe\n",
    "        \n",
    "        for i in range(3):\n",
    "            df_delay.loc[-1] = [demand, _model_type[weights], expected_delay[i], actual_delay[i], i]\n",
    "            df_thru.loc[-1] = [demand, _model_type[weights], expected_thru[i], actual_thru[i], i]\n",
    "            df_delay.index += 1\n",
    "            df_thru.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.to_pickle(DF_PATH + \"delay_comparison.pkl\")\n",
    "df_thru.to_pickle(DF_PATH + \"throughput_comparison.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
