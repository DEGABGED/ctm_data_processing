{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "from ctmmodels.const import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "currdir = os.getcwd()\n",
    "regex_name = r'(([A-Z])\\w+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS FOR EACH PROCESSING\n",
    "\n",
    "IMAGE_PATH = 'graphs/experiments-3'\n",
    "DF_PATH = 'experiments-final3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY_ZONE_MAPPING = {'30': (2, 2, 0), '22': (3, 1, 2), '2c': (2, 0, 0), '28': (2, 2, 1), '25': (3, 2, 1), '26': (3, 1, 1), '27': (3, 0, 1), '20': (2, 2, 2), '21': (3, 2, 2), '1e': (3, 1, 2), '23': (3, 0, 2), '24': (2, 0, 1), '29': (3, 2, 1), '1a': (3, 1, 3), '0': (1, 0, 3), '3': (3, 1, 0), '2': (3, 2, 0), '5': (1, 0, 0), '1d': (3, 2, 2), '7': (2, 1, 1), '1f': (3, 0, 2), '9': (3, 1, 1), '8': (3, 2, 1), '3a': (3, 1, 3), '1c': (2, 0, 2), '4': (3, 0, 0), 'a': (3, 0, 1), '6': (1, 0, 1), '39': (3, 2, 3), '12': (1, 0, 2), '3b': (3, 0, 3), '1b': (3, 0, 3), 'b': (1, 0, 2), '13': (1, 0, 2), 'd': (3, 2, 2), '11': (1, 0, 3), '10': (1, 0, 3), 'c': (2, 1, 2), '38': (2, 0, 3), '15': (1, 0, 1), '14': (1, 0, 1), '17': (1, 0, 0), 'f': (3, 0, 2), '19': (3, 2, 3), '32': (3, 1, 0), '31': (3, 2, 0), '16': (1, 0, 0), '37': (3, 0, 3), '36': (3, 1, 3), '35': (3, 2, 3), '34': (2, 1, 3), '2d': (3, 2, 0), '2e': (3, 1, 0), '2f': (3, 0, 0), '1': (2, 1, 0), '2a': (3, 1, 1), '2b': (3, 0, 1), '18': (2, 2, 3), '33': (3, 0, 0), 'e': (3, 1, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_approach = SOUTHBOUND\n",
    "\n",
    "_approach_terms = [\n",
    "    'Left',\n",
    "    'Through',\n",
    "    'Right'\n",
    "]\n",
    "\n",
    "_cell_path = [\n",
    "    (CELL_SOURCE,0,_approach),\n",
    "    (CELL_NORMAL,0,_approach),\n",
    "    (CELL_NORMAL,1,_approach),\n",
    "    (CELL_NORMAL,2,_approach),\n",
    "    (CELL_MOVEMENT,THROUGH_TURN,_approach),\n",
    "    S_mapping((CELL_MOVEMENT,THROUGH_TURN,_approach))[0]\n",
    "]\n",
    "\n",
    "_movement_labels = {\n",
    "    (2,LEFT_TURN,NORTHBOUND): 'NBL',\n",
    "    (2,RIGHT_TURN,NORTHBOUND): 'NBR',\n",
    "    (2,THROUGH_TURN,NORTHBOUND): 'NBT',\n",
    "    (2,LEFT_TURN,SOUTHBOUND): 'SBL',\n",
    "    (2,RIGHT_TURN,SOUTHBOUND): 'SBR',\n",
    "    (2,THROUGH_TURN,SOUTHBOUND): 'SBT',\n",
    "    (2,LEFT_TURN,EASTBOUND): 'EBL',\n",
    "    (2,RIGHT_TURN,EASTBOUND): 'EBR',\n",
    "    (2,THROUGH_TURN,EASTBOUND): 'EBT',\n",
    "    (2,LEFT_TURN,WESTBOUND): 'WBL',\n",
    "    (2,RIGHT_TURN,WESTBOUND): 'WBR',\n",
    "    (2,THROUGH_TURN,WESTBOUND): 'WBT',\n",
    "}\n",
    "\n",
    "_demands = [\n",
    "    450,\n",
    "    900,\n",
    "    (450, 900),\n",
    "    (900, 1800)\n",
    "]\n",
    "\n",
    "_weights = [\n",
    "    (1, 0, 0),\n",
    "    (0, 1, 0),\n",
    "    (0, 0, 1),\n",
    "    (0.5, 0.5, 0),\n",
    "    (0, 0.5, 0.5),\n",
    "    (0.5, 0, 0.5),\n",
    "    (0.33, 0.33, 0.33),\n",
    "    (0, 0, 0)\n",
    "]\n",
    "\n",
    "_model_type = {\n",
    "    (1, 0, 0): 'Delay priority',\n",
    "    (0, 1, 0): 'Throughput priority',\n",
    "    (0, 0, 1): 'Flow priority',\n",
    "    (0.5, 0.5, 0): 'Delay-Throughput priority',\n",
    "    (0, 0.5, 0.5): 'Throughput-Flow priority',\n",
    "    (0.5, 0, 0.5): 'Delay-Flow priority',\n",
    "    (0.33, 0.33, 0.33): 'Equal priority',\n",
    "    (0, 0, 0): 'Parent model',\n",
    "}\n",
    "\n",
    "_col_rename = {\n",
    "    'Runtime': 'runtime',\n",
    "    'Delay': 'delay',\n",
    "    'Throughput': 'throughput',\n",
    "    'ObjValue': 'objective_value'\n",
    "}\n",
    "\n",
    "def movement_paths(approach):\n",
    "    return [\n",
    "        [\n",
    "            (CELL_SOURCE,0,approach),\n",
    "            (CELL_NORMAL,0,approach),\n",
    "            (CELL_NORMAL,1,approach),\n",
    "            (CELL_NORMAL,2,approach),\n",
    "            (CELL_MOVEMENT,LEFT_TURN,approach),\n",
    "            S_mapping((CELL_MOVEMENT,LEFT_TURN,approach))[0]\n",
    "        ],\n",
    "        [\n",
    "            (CELL_SOURCE,0,approach),\n",
    "            (CELL_NORMAL,0,approach),\n",
    "            (CELL_NORMAL,1,approach),\n",
    "            (CELL_NORMAL,2,approach),\n",
    "            (CELL_MOVEMENT,THROUGH_TURN,approach),\n",
    "            S_mapping((CELL_MOVEMENT,THROUGH_TURN,approach))[0]\n",
    "        ],\n",
    "        [\n",
    "            (CELL_SOURCE,0,approach),\n",
    "            (CELL_NORMAL,0,approach),\n",
    "            (CELL_NORMAL,1,approach),\n",
    "            (CELL_NORMAL,2,approach),\n",
    "            (CELL_MOVEMENT,RIGHT_TURN,approach),\n",
    "            S_mapping((CELL_MOVEMENT,RIGHT_TURN,approach))[0]\n",
    "        ]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments Results Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = currdir + '/{}sim-results/result_d450_a0.5_b0.5_c0.xls'.format(DF_PATH)\n",
    "df_tmp = pd.read_excel(filename, sheet_name='Speed').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>0x20 - approach2_lane3</th>\n",
       "      <th>0x7 - approach1_lane2</th>\n",
       "      <th>0x25 - approach1_lane1</th>\n",
       "      <th>0x16 - exit0_lane3</th>\n",
       "      <th>0x32 - approach0_lane3</th>\n",
       "      <th>0x2 - approach0_lane2</th>\n",
       "      <th>0x28 - approach1_lane3</th>\n",
       "      <th>0x17 - exit0_lane1</th>\n",
       "      <th>0x1d - approach2_lane1</th>\n",
       "      <th>...</th>\n",
       "      <th>0x29 - approach1_lane3</th>\n",
       "      <th>0x10 - exit3_lane3</th>\n",
       "      <th>0x12 - exit2_lane3</th>\n",
       "      <th>0x13 - exit2_lane1</th>\n",
       "      <th>0x14 - exit1_lane3</th>\n",
       "      <th>0x2e - approach0_lane1</th>\n",
       "      <th>0x18 - approach3_lane3</th>\n",
       "      <th>0xc - approach2_lane2</th>\n",
       "      <th>0xb - exit2_lane2</th>\n",
       "      <th>0x2a - approach1_lane3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>77.760000</td>\n",
       "      <td>10.407273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.800000</td>\n",
       "      <td>76.406400</td>\n",
       "      <td>33.145263</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.275826</td>\n",
       "      <td>...</td>\n",
       "      <td>92.091429</td>\n",
       "      <td>116.640000</td>\n",
       "      <td>90.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.892364</td>\n",
       "      <td>46.505354</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.521679</td>\n",
       "      <td>66.461538</td>\n",
       "      <td>76.924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>77.760000</td>\n",
       "      <td>8.427975</td>\n",
       "      <td>16.414476</td>\n",
       "      <td>82.800000</td>\n",
       "      <td>70.592870</td>\n",
       "      <td>32.919273</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>55.296000</td>\n",
       "      <td>8.695322</td>\n",
       "      <td>...</td>\n",
       "      <td>89.949767</td>\n",
       "      <td>88.868571</td>\n",
       "      <td>90.720000</td>\n",
       "      <td>61.560000</td>\n",
       "      <td>84.808421</td>\n",
       "      <td>42.714157</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.958310</td>\n",
       "      <td>58.529032</td>\n",
       "      <td>76.924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180</td>\n",
       "      <td>77.760000</td>\n",
       "      <td>8.342672</td>\n",
       "      <td>9.604755</td>\n",
       "      <td>83.671579</td>\n",
       "      <td>72.276324</td>\n",
       "      <td>24.490667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>55.296000</td>\n",
       "      <td>4.764061</td>\n",
       "      <td>...</td>\n",
       "      <td>87.162592</td>\n",
       "      <td>85.945263</td>\n",
       "      <td>71.950345</td>\n",
       "      <td>53.110588</td>\n",
       "      <td>80.568000</td>\n",
       "      <td>43.111087</td>\n",
       "      <td>77.5584</td>\n",
       "      <td>4.515267</td>\n",
       "      <td>60.480000</td>\n",
       "      <td>75.975111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>77.760000</td>\n",
       "      <td>7.223852</td>\n",
       "      <td>7.345705</td>\n",
       "      <td>89.081379</td>\n",
       "      <td>70.528985</td>\n",
       "      <td>11.629477</td>\n",
       "      <td>76.9248</td>\n",
       "      <td>56.552727</td>\n",
       "      <td>3.858202</td>\n",
       "      <td>...</td>\n",
       "      <td>83.110612</td>\n",
       "      <td>89.341277</td>\n",
       "      <td>72.110769</td>\n",
       "      <td>51.984000</td>\n",
       "      <td>84.404571</td>\n",
       "      <td>42.891762</td>\n",
       "      <td>86.1760</td>\n",
       "      <td>4.835312</td>\n",
       "      <td>58.800000</td>\n",
       "      <td>71.944058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>80.441379</td>\n",
       "      <td>7.316391</td>\n",
       "      <td>6.403170</td>\n",
       "      <td>86.286316</td>\n",
       "      <td>71.312640</td>\n",
       "      <td>9.436143</td>\n",
       "      <td>76.9248</td>\n",
       "      <td>58.206316</td>\n",
       "      <td>3.381750</td>\n",
       "      <td>...</td>\n",
       "      <td>83.972842</td>\n",
       "      <td>91.966154</td>\n",
       "      <td>72.576000</td>\n",
       "      <td>54.052683</td>\n",
       "      <td>84.254118</td>\n",
       "      <td>41.628203</td>\n",
       "      <td>86.1760</td>\n",
       "      <td>4.644216</td>\n",
       "      <td>57.906383</td>\n",
       "      <td>72.117000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t  0x20 - approach2_lane3  0x7 - approach1_lane2  0x25 - approach1_lane1  \\\n",
       "0   60               77.760000              10.407273                0.000000   \n",
       "1  120               77.760000               8.427975               16.414476   \n",
       "2  180               77.760000               8.342672                9.604755   \n",
       "3  240               77.760000               7.223852                7.345705   \n",
       "4  300               80.441379               7.316391                6.403170   \n",
       "\n",
       "   0x16 - exit0_lane3  0x32 - approach0_lane3  0x2 - approach0_lane2  \\\n",
       "0           82.800000               76.406400              33.145263   \n",
       "1           82.800000               70.592870              32.919273   \n",
       "2           83.671579               72.276324              24.490667   \n",
       "3           89.081379               70.528985              11.629477   \n",
       "4           86.286316               71.312640               9.436143   \n",
       "\n",
       "   0x28 - approach1_lane3  0x17 - exit0_lane1  0x1d - approach2_lane1  ...  \\\n",
       "0                  0.0000            0.000000               29.275826  ...   \n",
       "1                  0.0000           55.296000                8.695322  ...   \n",
       "2                  0.0000           55.296000                4.764061  ...   \n",
       "3                 76.9248           56.552727                3.858202  ...   \n",
       "4                 76.9248           58.206316                3.381750  ...   \n",
       "\n",
       "   0x29 - approach1_lane3  0x10 - exit3_lane3  0x12 - exit2_lane3  \\\n",
       "0               92.091429          116.640000           90.720000   \n",
       "1               89.949767           88.868571           90.720000   \n",
       "2               87.162592           85.945263           71.950345   \n",
       "3               83.110612           89.341277           72.110769   \n",
       "4               83.972842           91.966154           72.576000   \n",
       "\n",
       "   0x13 - exit2_lane1  0x14 - exit1_lane3  0x2e - approach0_lane1  \\\n",
       "0            0.000000           87.892364               46.505354   \n",
       "1           61.560000           84.808421               42.714157   \n",
       "2           53.110588           80.568000               43.111087   \n",
       "3           51.984000           84.404571               42.891762   \n",
       "4           54.052683           84.254118               41.628203   \n",
       "\n",
       "   0x18 - approach3_lane3  0xc - approach2_lane2  0xb - exit2_lane2  \\\n",
       "0                  0.0000               9.521679          66.461538   \n",
       "1                  0.0000               4.958310          58.529032   \n",
       "2                 77.5584               4.515267          60.480000   \n",
       "3                 86.1760               4.835312          58.800000   \n",
       "4                 86.1760               4.644216          57.906383   \n",
       "\n",
       "   0x2a - approach1_lane3  \n",
       "0               76.924800  \n",
       "1               76.924800  \n",
       "2               75.975111  \n",
       "3               71.944058  \n",
       "4               72.117000  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out some of the rows\n",
    "\n",
    "delay_rows = [\"{} Delay\".format(d) for d in range(60,601,60)]\n",
    "delay_rename = dict([\n",
    "    (\"{} Delay\".format(d), d)\n",
    "    for d in range(60,601,60)\n",
    "])\n",
    "\n",
    "thru_rows = [\"{} Throughput\".format(d) for d in range(60,601,60)]\n",
    "thru_rename = dict([\n",
    "    (\"{} Throughput\".format(d), d)\n",
    "    for d in range(60,601,60)\n",
    "])\n",
    "\n",
    "vol_rows = [d for d in range(60,601,60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 approach zones, 12 exit zones\n"
     ]
    }
   ],
   "source": [
    "# Filter out some of the columns\n",
    "\n",
    "survey_zones = df_tmp.columns.values[1:]\n",
    "\n",
    "entrances = [x for x in survey_zones if 'approach' in x]\n",
    "exits = [y for y in survey_zones if 'exit' in y]\n",
    "\n",
    "print(\"{} approach zones, {} exit zones\".format(len(entrances), len(exits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_approach = re.compile('0x(\\w+) - approach.*')\n",
    "reg_exit = re.compile('0x(\\w+) - exit.*')\n",
    "\n",
    "entrances_rename = dict([\n",
    "    (k, SURVEY_ZONE_MAPPING[reg_approach.match(k).group(1)])\n",
    "    for k in entrances\n",
    "])\n",
    "\n",
    "exits_rename = dict([\n",
    "    (k, SURVEY_ZONE_MAPPING[reg_exit.match(k).group(1)])\n",
    "    for k in exits\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightlist = [\n",
    "    (1, 0, 0),\n",
    "    (0, 1, 0),\n",
    "    (0, 0, 1),\n",
    "    (0.5, 0.5, 0),\n",
    "    (0, 0.5, 0.5),\n",
    "    (0.5, 0, 0.5),\n",
    "    (0.33, 0.33, 0.33),\n",
    "    (0, 0, 0)\n",
    "]\n",
    "\n",
    "demands = [\n",
    "    450,\n",
    "    900,\n",
    "    (450, 900),\n",
    "    (900, 1800)\n",
    "]\n",
    "\n",
    "_model_type = {\n",
    "    (1, 0, 0): 'Delay priority',\n",
    "    (0, 1, 0): 'Throughput priority',\n",
    "    (0, 0, 1): 'Flow priority',\n",
    "    (0.5, 0.5, 0): 'Delay-Throughput priority',\n",
    "    (0, 0.5, 0.5): 'Throughput-Flow priority',\n",
    "    (0.5, 0, 0.5): 'Delay-Flow priority',\n",
    "    (0.33, 0.33, 0.33): 'Equal priority',\n",
    "    (0, 0, 0): 'Parent model',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/localsim/.virtualenvs/thesis/local/lib/python2.7/site-packages/pandas/core/generic.py:6586: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "total_thru_dfs = []\n",
    "total_delay_dfs = []\n",
    "ave_delay_dfs = []\n",
    "\n",
    "for demand in demands:\n",
    "    for weights in weightlist:\n",
    "\n",
    "        partial_fn = 'old' if weights == (0, 0, 0) else 'a{}_b{}_c{}'.format(*weights)\n",
    "        filename = currdir + '/{}sim-results/result_d{}_{}.xls'.format(DF_PATH, demand, partial_fn)\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='Speed').fillna(0)\n",
    "\n",
    "        # Get the cumulative delays\n",
    "\n",
    "        df_tmp1 = df_tmp[df_tmp.t.isin(delay_rows)]\n",
    "        df_tmp1['t'].replace(delay_rename, inplace=True)\n",
    "        df_tmp1 = df_tmp1.sort_values(by='t').set_index('t')[entrances].stack().reset_index()\n",
    "        df_tmp1['level_1'] = df_tmp1['level_1'].map(entrances_rename)\n",
    "        df_tmp1 = df_tmp1.groupby(['t', 'level_1']).sum().reset_index()\n",
    "\n",
    "        df_cumdelay = df_tmp1.pivot(index='t', columns='level_1', values=0)\n",
    "        df_cumdelay.to_pickle(currdir + '/{}cumu-delay/delay_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "        \n",
    "        # Get the cumulative throughputs\n",
    "\n",
    "        df_tmp3 = df_tmp[df_tmp.t.isin(thru_rows)]\n",
    "#         if weights == (0, 0, 0):\n",
    "#             for col in ['0x11 - exit3_lane1', '0x15 - exit1_lane1', '0x17 - exit0_lane1', '0x13 - exit2_lane1']:\n",
    "#                 if col not in df_tmp3.columns:\n",
    "#                     df_tmp3[col] = 0\n",
    "        df_tmp3['t'].replace(thru_rename, inplace=True)\n",
    "        df_tmp3 = df_tmp3.sort_values(by='t').set_index('t')[exits].stack().reset_index()\n",
    "        df_tmp3['level_1'] = df_tmp3['level_1'].map(exits_rename)\n",
    "        df_tmp3 = df_tmp3.groupby(['t', 'level_1']).sum().reset_index()\n",
    "\n",
    "        df_cumthru = df_tmp3.pivot(index='t', columns='level_1', values=0)\n",
    "        df_cumthru.to_pickle(currdir + '/{}cumu-thru/thru_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "        \n",
    "        # Get volumes\n",
    "        \n",
    "        df_tmp = pd.read_excel(filename, sheet_name='Volume').fillna(0)\n",
    "        df_tmp1 = df_tmp[df_tmp.t.isin(vol_rows)]\n",
    "        df_tmp1 = df_tmp1.sort_values(by='t').set_index('t')[entrances].stack().reset_index()\n",
    "        df_tmp1['level_1'] = df_tmp1['level_1'].map(entrances_rename)\n",
    "        df_tmp1 = df_tmp1.groupby(['t', 'level_1']).sum().reset_index()\n",
    "\n",
    "        df_volume = df_tmp1.pivot(index='t', columns='level_1', values=0)\n",
    "        df_volume.to_pickle(currdir + '/{}actual-volume/vol_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "\n",
    "        # Get aggregate values\n",
    "\n",
    "        df_total_thru_tmp = df_cumthru.loc[600, :].reset_index().set_index('level_1').T\n",
    "        df_total_thru_tmp['demand'] = [demand]\n",
    "        df_total_thru_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_total_thru_tmp['alpha'] = weights[0]\n",
    "        df_total_thru_tmp['beta'] = weights[1]\n",
    "        df_total_thru_tmp['gamma'] = weights[2]\n",
    "        df_total_thru_tmp['model_type'] = _model_type[weights]\n",
    "        total_thru_dfs.append(df_total_thru_tmp)\n",
    "\n",
    "        df_total_delay_tmp = df_cumdelay.loc[600, :].reset_index().set_index('level_1').T\n",
    "        df_total_delay_tmp['demand'] = [demand]\n",
    "        df_total_delay_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_total_delay_tmp['alpha'] = weights[0]\n",
    "        df_total_delay_tmp['beta'] = weights[1]\n",
    "        df_total_delay_tmp['gamma'] = weights[2]\n",
    "        df_total_delay_tmp['model_type'] = _model_type[weights]\n",
    "        total_delay_dfs.append(df_total_delay_tmp)\n",
    "\n",
    "        df_tmp2 = df_tmp[df_tmp.t == 'Average Delay'][entrances].rename(columns=entrances_rename).stack().reset_index()\n",
    "        df_ave_delay_tmp = df_tmp2.groupby('level_1').mean().reset_index().pivot(index='level_0', columns='level_1', values=0)\n",
    "        df_ave_delay_tmp['demand'] = [demand]\n",
    "        df_ave_delay_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_ave_delay_tmp['alpha'] = weights[0]\n",
    "        df_ave_delay_tmp['beta'] = weights[1]\n",
    "        df_ave_delay_tmp['gamma'] = weights[2]\n",
    "        df_ave_delay_tmp['model_type'] = _model_type[weights]\n",
    "        ave_delay_dfs.append(df_ave_delay_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_thru = pd.concat(total_thru_dfs).reset_index().iloc[:, 1:]\n",
    "df_total_thru.to_pickle(currdir + '/{}total_throughput.pkl'.format(DF_PATH))\n",
    "\n",
    "df_total_delay = pd.concat(total_delay_dfs).reset_index().iloc[:, 1:]\n",
    "df_total_delay.to_pickle(currdir + '/{}total_delay.pkl'.format(DF_PATH))\n",
    "\n",
    "df_ave_delay = pd.concat(ave_delay_dfs).reset_index().iloc[:, 1:]\n",
    "df_ave_delay.to_pickle(currdir + '/{}ave_delay.pkl'.format(DF_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greentimes from Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting variables for image generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing greentimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_greentime_map(dfg, title=\"Greentime maps\", headless=False, filename='greentime.png', movements=True):\n",
    "    fig, axs = plt.subplots(figsize=(10,5))\n",
    "\n",
    "    dfg_matrix = dfg.T\n",
    "    if movements:\n",
    "        dfg_matrix = dfg_matrix.reindex(index=[\n",
    "            (2,LEFT_TURN,NORTHBOUND), (2,RIGHT_TURN,NORTHBOUND), (2,THROUGH_TURN,NORTHBOUND),\n",
    "            (2,LEFT_TURN,SOUTHBOUND), (2,RIGHT_TURN,SOUTHBOUND), (2,THROUGH_TURN,SOUTHBOUND),\n",
    "            (2,LEFT_TURN,EASTBOUND), (2,RIGHT_TURN,EASTBOUND), (2,THROUGH_TURN,EASTBOUND),\n",
    "            (2,LEFT_TURN,WESTBOUND), (2,RIGHT_TURN,WESTBOUND), (2,THROUGH_TURN,WESTBOUND),\n",
    "        ]).rename(index=_movement_labels).rename_axis(index='Movements', columns='Timesteps')\n",
    "    sns.heatmap(data=dfg_matrix, cbar=False)\n",
    "    \n",
    "    fig.suptitle(title, fontsize=18)\n",
    "    \n",
    "    if headless:\n",
    "        fig.savefig(IMAGE_PATH + filename)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, filename):\n",
    "    df.to_pickle(DF_PATH + filename + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_demands = [\n",
    "    450,\n",
    "    900,\n",
    "    (450, 900),\n",
    "    (900, 1800)\n",
    "]\n",
    "\n",
    "_weights = [\n",
    "    (1, 0, 0),\n",
    "    (0, 1, 0),\n",
    "    (0, 0, 1),\n",
    "    (0.5, 0.5, 0),\n",
    "    (0, 0.5, 0.5),\n",
    "    (0.5, 0, 0.5),\n",
    "    (0.33, 0.33, 0.33),\n",
    "    (0, 0, 0)\n",
    "]\n",
    "\n",
    "for demand in _demands:\n",
    "    for weights in _weights:\n",
    "        if weights == (0,0,0):\n",
    "            df_e0 = pd.read_pickle(DF_PATH + 'greentimes/initial/greentimes_d{}_old.pkl'.format(demand))\n",
    "            df_e1 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch1_old.pkl'.format(demand))\n",
    "            df_e2 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch2_old.pkl'.format(demand))\n",
    "            df_e3 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch3_old.pkl'.format(demand))\n",
    "            subtitle = 'Old model'\n",
    "            filename = 'old'\n",
    "        else:\n",
    "            df_e0 = pd.read_pickle(DF_PATH + 'greentimes/initial/greentimes_d{}_new_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "            df_e1 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch1_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "            df_e2 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch2_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "            df_e3 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch3_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "            subtitle = 'New model ({})'.format(_model_type[weights])\n",
    "            filename = 'a{}_b{}_c{}'.format(*weights)\n",
    "            \n",
    "        plot_greentime_map(\n",
    "            df_e0,\n",
    "            title='Greentimes for demand {} and {} (Initial)'.format(demand, subtitle),\n",
    "            headless=True,\n",
    "            filename='d{}_{}_epoch0.png'.format(demand, filename)\n",
    "        )\n",
    "\n",
    "        plot_greentime_map(\n",
    "            df_e1,\n",
    "            title='Greentimes for demand {} and {} (Epoch 1)'.format(demand, subtitle),\n",
    "            headless=True,\n",
    "            filename='d{}_{}_epoch1.png'.format(demand, filename)\n",
    "        )\n",
    "        \n",
    "        plot_greentime_map(\n",
    "            df_e2,\n",
    "            title='Greentimes for demand {} and {} (Epoch 2)'.format(demand, subtitle),\n",
    "            headless=True,\n",
    "            filename='d{}_{}_epoch2.png'.format(demand, filename)\n",
    "        )\n",
    "        \n",
    "        plot_greentime_map(\n",
    "            df_e3,\n",
    "            title='Greentimes for demand {} and {} (Epoch 3)'.format(demand, subtitle),\n",
    "            headless=True,\n",
    "            filename='d{}_{}_epoch3.png'.format(demand, filename)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results from MILP Realtime Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining across epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results_dflist = []\n",
    "\n",
    "for demand in _demands:\n",
    "    for weights in _weights:\n",
    "        if weights == (0,0,0):\n",
    "            df_e1 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch1_old.csv'.format(demand))\n",
    "            df_e2 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch2_old.csv'.format(demand))\n",
    "            df_e3 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch3_old.csv'.format(demand))\n",
    "        else:\n",
    "            df_e1 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch1_a{}_b{}_c{}.csv'.format(demand, *weights))\n",
    "            df_e2 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch2_a{}_b{}_c{}.csv'.format(demand, *weights))\n",
    "            df_e3 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch3_a{}_b{}_c{}.csv'.format(demand, *weights))\n",
    "\n",
    "        df_e1 = df_e1.rename(columns=_col_rename)\n",
    "        df_e1['demand'] = [demand]\n",
    "        df_e1['new_model'] = weights != (0,0,0)\n",
    "        df_e1['alpha'] = weights[0]\n",
    "        df_e1['beta'] = weights[1]\n",
    "        df_e1['gamma'] = weights[2]\n",
    "        df_e1['model_type'] = _model_type[weights]\n",
    "        df_e1['epoch'] = 1\n",
    "        \n",
    "        df_e2 = df_e2.rename(columns=_col_rename)\n",
    "        df_e2['demand'] = [demand]\n",
    "        df_e2['new_model'] = weights != (0,0,0)\n",
    "        df_e2['alpha'] = weights[0]\n",
    "        df_e2['beta'] = weights[1]\n",
    "        df_e2['gamma'] = weights[2]\n",
    "        df_e2['model_type'] = _model_type[weights]\n",
    "        df_e2['epoch'] = 2\n",
    "        \n",
    "        df_e3 = df_e3.rename(columns=_col_rename)\n",
    "        df_e3['demand'] = [demand]\n",
    "        df_e3['new_model'] = weights != (0,0,0)\n",
    "        df_e3['alpha'] = weights[0]\n",
    "        df_e3['beta'] = weights[1]\n",
    "        df_e3['gamma'] = weights[2]\n",
    "        df_e3['model_type'] = _model_type[weights]\n",
    "        df_e3['epoch'] = 3\n",
    "        \n",
    "        _results_dflist.append(pd.concat([df_e1, df_e2, df_e3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(_results_dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_results = pd.read_pickle(DF_PATH + 'results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_results['demand'] = df_initial_results.apply(lambda row: \n",
    "                                                        int(row['demand_ns']) if row['demand_ns'] == row['demand_ew']\n",
    "                                                        else (int(row['demand_ns']), int(row['demand_ew']))\n",
    "                                                        , axis=1)\n",
    "\n",
    "df_initial_results['new_model'] = df_initial_results.apply(lambda row: row['alpha'] != 0, axis=1)\n",
    "\n",
    "df_initial_results['model_type'] = df_initial_results.apply(lambda row: _model_type[\n",
    "    (row['alpha'], row['beta'], row['gamma'])\n",
    "], axis=1)\n",
    "\n",
    "df_initial_results['epoch'] = 0\n",
    "\n",
    "df_initial_results['delay'] = df_initial_results['delay'].apply(lambda x: 2*x)\n",
    "\n",
    "df_initial_results = df_initial_results[[\n",
    "    'runtime',\n",
    "    'delay',\n",
    "    'throughput',\n",
    "    'objective_value',\n",
    "    'demand',\n",
    "    'new_model',\n",
    "    'alpha',\n",
    "    'beta',\n",
    "    'gamma',\n",
    "    'model_type',\n",
    "    'epoch'\n",
    "]]\n",
    "\n",
    "df = df.rename(columns={'obj-value': 'objective_value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_initial_results, df]).sort_values(by=['epoch', 'demand', 'model_type'])\n",
    "\n",
    "save_df(df_final, 'milp-realtime-results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected vs Actual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_dfs = []\n",
    "throughput_dfs = []\n",
    "\n",
    "df_milp = pd.read_pickle(DF_PATH + 'milp-realtime-results.pkl')\n",
    "df_delay = pd.DataFrame(columns=['demand', 'model_type', 'expected', 'actual', 'epoch'])\n",
    "df_thru = pd.DataFrame(columns=['demand', 'model_type', 'expected', 'actual', 'epoch'])\n",
    "\n",
    "for demand in _demands:\n",
    "    for weights in _weights:\n",
    "\n",
    "        # Get actual values\n",
    "        \n",
    "        df_cumdelay_tmp = pd.read_pickle(DF_PATH + 'cumu-delay/delay_d{}_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "        df_instdelay_tmp = df_cumdelay_tmp.diff()\n",
    "        df_instdelay_tmp.loc[60, :] = df_cumdelay_tmp.loc[60, :]\n",
    "        actual_delay = list(df_instdelay_tmp.sum(axis=1)[[60, 240, 420]])\n",
    "        \n",
    "        df_cumthru_tmp = pd.read_pickle(DF_PATH + 'cumu-thru/thru_d{}_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "        df_instthru_tmp = df_cumthru_tmp.diff()\n",
    "        df_instthru_tmp.loc[60, :] = df_cumthru_tmp.loc[60, :]\n",
    "        actual_thru = list(df_instthru_tmp.sum(axis=1)[[60, 240, 420]])\n",
    "\n",
    "        # Get expected values\n",
    "        \n",
    "        expected_delay = list(df_milp[(df_milp.demand == demand) & (df_milp.model_type == _model_type[weights])].delay)\n",
    "        expected_thru = list(df_milp[(df_milp.demand == demand) & (df_milp.model_type == _model_type[weights])].throughput)\n",
    "        \n",
    "        # Combine into a dataframe\n",
    "        \n",
    "        for i in range(3):\n",
    "            df_delay.loc[-1] = [demand, _model_type[weights], expected_delay[i], actual_delay[i], i]\n",
    "            df_thru.loc[-1] = [demand, _model_type[weights], expected_thru[i], actual_thru[i], i]\n",
    "            df_delay.index += 1\n",
    "            df_thru.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.to_pickle(DF_PATH + \"delay_comparison.pkl\")\n",
    "df_thru.to_pickle(DF_PATH + \"throughput_comparison.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
