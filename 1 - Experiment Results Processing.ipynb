{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "from ctmmodels.const import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "currdir = os.getcwd()\n",
    "regex_name = r'(([A-Z])\\w+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS FOR EACH PROCESSING\n",
    "\n",
    "IMAGE_PATH = 'graphs/experiments-9/'\n",
    "DF_PATH = 'experiments-final9/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY_ZONE_MAPPING = {'30': (2, 2, 0), '22': (3, 1, 2), '2c': (2, 0, 0), '28': (2, 2, 1), '25': (3, 2, 1), '26': (3, 1, 1), '27': (3, 0, 1), '20': (2, 2, 2), '21': (3, 2, 2), '1e': (3, 1, 2), '23': (3, 0, 2), '24': (2, 0, 1), '29': (3, 2, 1), '1a': (3, 1, 3), '0': (1, 0, 3), '3': (3, 1, 0), '2': (3, 2, 0), '5': (1, 0, 0), '1d': (3, 2, 2), '7': (2, 1, 1), '1f': (3, 0, 2), '9': (3, 1, 1), '8': (3, 2, 1), '3a': (3, 1, 3), '1c': (2, 0, 2), '4': (3, 0, 0), 'a': (3, 0, 1), '6': (1, 0, 1), '39': (3, 2, 3), '12': (1, 0, 2), '3b': (3, 0, 3), '1b': (3, 0, 3), 'b': (1, 0, 2), '13': (1, 0, 2), 'd': (3, 2, 2), '11': (1, 0, 3), '10': (1, 0, 3), 'c': (2, 1, 2), '38': (2, 0, 3), '15': (1, 0, 1), '14': (1, 0, 1), '17': (1, 0, 0), 'f': (3, 0, 2), '19': (3, 2, 3), '32': (3, 1, 0), '31': (3, 2, 0), '16': (1, 0, 0), '37': (3, 0, 3), '36': (3, 1, 3), '35': (3, 2, 3), '34': (2, 1, 3), '2d': (3, 2, 0), '2e': (3, 1, 0), '2f': (3, 0, 0), '1': (2, 1, 0), '2a': (3, 1, 1), '2b': (3, 0, 1), '18': (2, 2, 3), '33': (3, 0, 0), 'e': (3, 1, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_approach = SOUTHBOUND\n",
    "\n",
    "_approach_terms = [\n",
    "    'Left',\n",
    "    'Through',\n",
    "    'Right'\n",
    "]\n",
    "\n",
    "_cell_path = [\n",
    "    (CELL_SOURCE,0,_approach),\n",
    "    (CELL_NORMAL,0,_approach),\n",
    "    (CELL_NORMAL,1,_approach),\n",
    "    (CELL_NORMAL,2,_approach),\n",
    "    (CELL_MOVEMENT,THROUGH_TURN,_approach),\n",
    "    S_mapping((CELL_MOVEMENT,THROUGH_TURN,_approach))[0]\n",
    "]\n",
    "\n",
    "_movement_labels = {\n",
    "    (2,LEFT_TURN,NORTHBOUND): 'NBL',\n",
    "    (2,RIGHT_TURN,NORTHBOUND): 'NBR',\n",
    "    (2,THROUGH_TURN,NORTHBOUND): 'NBT',\n",
    "    (2,LEFT_TURN,SOUTHBOUND): 'SBL',\n",
    "    (2,RIGHT_TURN,SOUTHBOUND): 'SBR',\n",
    "    (2,THROUGH_TURN,SOUTHBOUND): 'SBT',\n",
    "    (2,LEFT_TURN,EASTBOUND): 'EBL',\n",
    "    (2,RIGHT_TURN,EASTBOUND): 'EBR',\n",
    "    (2,THROUGH_TURN,EASTBOUND): 'EBT',\n",
    "    (2,LEFT_TURN,WESTBOUND): 'WBL',\n",
    "    (2,RIGHT_TURN,WESTBOUND): 'WBR',\n",
    "    (2,THROUGH_TURN,WESTBOUND): 'WBT',\n",
    "}\n",
    "\n",
    "_demands = [\n",
    "    450,\n",
    "    900,\n",
    "    (450, 900),\n",
    "    (900, 1800)\n",
    "]\n",
    "\n",
    "_weights = [\n",
    "    (1, 0, 0),\n",
    "    (0, 1, 0),\n",
    "    (0, 0, 1),\n",
    "    (0.5, 0.5, 0),\n",
    "    (0, 0.5, 0.5),\n",
    "    (0.5, 0, 0.5),\n",
    "    (0.33, 0.33, 0.33),\n",
    "    (0, 0, 0)\n",
    "]\n",
    "\n",
    "_model_type = {\n",
    "    (1, 0, 0): 'Delay priority',\n",
    "    (0, 1, 0): 'Throughput priority',\n",
    "    (0, 0, 1): 'Flow priority',\n",
    "    (0.5, 0.5, 0): 'Delay-Throughput priority',\n",
    "    (0, 0.5, 0.5): 'Throughput-Flow priority',\n",
    "    (0.5, 0, 0.5): 'Delay-Flow priority',\n",
    "    (0.33, 0.33, 0.33): 'Equal priority',\n",
    "    (0, 0, 0): 'Parent model',\n",
    "}\n",
    "\n",
    "_col_rename = {\n",
    "    'Runtime': 'runtime',\n",
    "    'Delay': 'delay',\n",
    "    'Throughput': 'throughput',\n",
    "    'ObjValue': 'objective_value',\n",
    "    'Average time': 'travel_time',\n",
    "    'Average speed': 'average_speed',\n",
    "}\n",
    "\n",
    "ROUTE_MAPPING = {\n",
    "    'approach0_lane1-North_to_East-exit1_lane1': ('North', 'Left'),\n",
    "    'approach0_lane2-North_to_South_Lane2_Lane3-exit2_lane2': ('North', 'Through'),\n",
    "    'approach0_lane3-North_to_West-exit3_lane3': ('North', 'Right'),\n",
    "    'approach1_lane1-East_to_South-exit2_lane1': ('East', 'Left'),\n",
    "    'approach1_lane2-East_to_West_Lane2_Lane3-exit3_lane2': ('East', 'Through'),\n",
    "    'approach1_lane3-East_to_North-exit0_lane3': ('East', 'Right'),\n",
    "    'approach2_lane1-South_to_West-exit3_lane1': ('South', 'Left'),\n",
    "    'approach2_lane2-South_to_North_Lane2_Lane3-exit0_lane2': ('South', 'Through'),\n",
    "    'approach2_lane3-South_to_East-exit1_lane3': ('South', 'Right'),\n",
    "    'approach3_lane1-West_to_North-exit0_lane1': ('West', 'Left'),\n",
    "    'approach3_lane2-West_to_East_Lane2_Lane3-exit1_lane2': ('West', 'Through'),\n",
    "    'approach3_lane3-West_to_South-exit2_lane3': ('West', 'Right')\n",
    "}\n",
    "\n",
    "def movement_paths(approach):\n",
    "    return [\n",
    "        [\n",
    "            (CELL_SOURCE,0,approach),\n",
    "            (CELL_NORMAL,0,approach),\n",
    "            (CELL_NORMAL,1,approach),\n",
    "            (CELL_NORMAL,2,approach),\n",
    "            (CELL_MOVEMENT,LEFT_TURN,approach),\n",
    "            S_mapping((CELL_MOVEMENT,LEFT_TURN,approach))[0]\n",
    "        ],\n",
    "        [\n",
    "            (CELL_SOURCE,0,approach),\n",
    "            (CELL_NORMAL,0,approach),\n",
    "            (CELL_NORMAL,1,approach),\n",
    "            (CELL_NORMAL,2,approach),\n",
    "            (CELL_MOVEMENT,THROUGH_TURN,approach),\n",
    "            S_mapping((CELL_MOVEMENT,THROUGH_TURN,approach))[0]\n",
    "        ],\n",
    "        [\n",
    "            (CELL_SOURCE,0,approach),\n",
    "            (CELL_NORMAL,0,approach),\n",
    "            (CELL_NORMAL,1,approach),\n",
    "            (CELL_NORMAL,2,approach),\n",
    "            (CELL_MOVEMENT,RIGHT_TURN,approach),\n",
    "            S_mapping((CELL_MOVEMENT,RIGHT_TURN,approach))[0]\n",
    "        ]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments Results Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = currdir + '/{}sim-results/result_d450_a0.5_b0.5_c0.xls'.format(DF_PATH)\n",
    "df_tmp = pd.read_excel(filename, sheet_name='Speed').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>0x20 - approach2_lane3</th>\n",
       "      <th>0x7 - approach1_lane2</th>\n",
       "      <th>0x25 - approach1_lane1</th>\n",
       "      <th>0x19 - approach3_lane3</th>\n",
       "      <th>0x32 - approach0_lane3</th>\n",
       "      <th>0x2 - approach0_lane2</th>\n",
       "      <th>0x28 - approach1_lane3</th>\n",
       "      <th>0x17 - exit0_lane1</th>\n",
       "      <th>0x1d - approach2_lane1</th>\n",
       "      <th>...</th>\n",
       "      <th>0x15 - exit1_lane1</th>\n",
       "      <th>0x10 - exit3_lane3</th>\n",
       "      <th>0x12 - exit2_lane3</th>\n",
       "      <th>0x13 - exit2_lane1</th>\n",
       "      <th>0x14 - exit1_lane3</th>\n",
       "      <th>0x2e - approach0_lane1</th>\n",
       "      <th>0x18 - approach3_lane3</th>\n",
       "      <th>0xc - approach2_lane2</th>\n",
       "      <th>0xb - exit2_lane2</th>\n",
       "      <th>0x2a - approach1_lane3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.152381</td>\n",
       "      <td>43.088000</td>\n",
       "      <td>77.126400</td>\n",
       "      <td>74.284000</td>\n",
       "      <td>35.702929</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>103.680000</td>\n",
       "      <td>32.064000</td>\n",
       "      <td>...</td>\n",
       "      <td>62.208000</td>\n",
       "      <td>102.060000</td>\n",
       "      <td>77.760000</td>\n",
       "      <td>82.080000</td>\n",
       "      <td>107.424000</td>\n",
       "      <td>53.979429</td>\n",
       "      <td>77.558400</td>\n",
       "      <td>10.990057</td>\n",
       "      <td>55.542857</td>\n",
       "      <td>75.048585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.789286</td>\n",
       "      <td>35.253818</td>\n",
       "      <td>77.992989</td>\n",
       "      <td>73.467692</td>\n",
       "      <td>33.463262</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>63.803077</td>\n",
       "      <td>21.495419</td>\n",
       "      <td>...</td>\n",
       "      <td>56.552727</td>\n",
       "      <td>104.976000</td>\n",
       "      <td>74.225455</td>\n",
       "      <td>82.080000</td>\n",
       "      <td>94.785882</td>\n",
       "      <td>53.136000</td>\n",
       "      <td>86.176000</td>\n",
       "      <td>6.420397</td>\n",
       "      <td>55.741935</td>\n",
       "      <td>75.416471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.412539</td>\n",
       "      <td>26.540897</td>\n",
       "      <td>80.211456</td>\n",
       "      <td>73.941677</td>\n",
       "      <td>20.850735</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>57.202759</td>\n",
       "      <td>7.767860</td>\n",
       "      <td>...</td>\n",
       "      <td>54.308571</td>\n",
       "      <td>99.977143</td>\n",
       "      <td>78.624000</td>\n",
       "      <td>62.767059</td>\n",
       "      <td>92.775273</td>\n",
       "      <td>48.032542</td>\n",
       "      <td>89.490462</td>\n",
       "      <td>6.018364</td>\n",
       "      <td>56.492308</td>\n",
       "      <td>75.663738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.131486</td>\n",
       "      <td>19.972120</td>\n",
       "      <td>82.102297</td>\n",
       "      <td>74.745391</td>\n",
       "      <td>21.917401</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>55.296000</td>\n",
       "      <td>4.773797</td>\n",
       "      <td>...</td>\n",
       "      <td>53.512258</td>\n",
       "      <td>104.976000</td>\n",
       "      <td>78.783158</td>\n",
       "      <td>62.380800</td>\n",
       "      <td>96.681600</td>\n",
       "      <td>36.714753</td>\n",
       "      <td>89.490462</td>\n",
       "      <td>6.017104</td>\n",
       "      <td>54.443836</td>\n",
       "      <td>75.841352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>77.76</td>\n",
       "      <td>8.904618</td>\n",
       "      <td>17.397326</td>\n",
       "      <td>81.800727</td>\n",
       "      <td>74.284000</td>\n",
       "      <td>21.914320</td>\n",
       "      <td>76.9248</td>\n",
       "      <td>56.233220</td>\n",
       "      <td>3.855391</td>\n",
       "      <td>...</td>\n",
       "      <td>53.104390</td>\n",
       "      <td>93.312000</td>\n",
       "      <td>79.380000</td>\n",
       "      <td>54.720000</td>\n",
       "      <td>93.651692</td>\n",
       "      <td>29.220864</td>\n",
       "      <td>89.490462</td>\n",
       "      <td>5.919330</td>\n",
       "      <td>55.148936</td>\n",
       "      <td>72.766703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t  0x20 - approach2_lane3  0x7 - approach1_lane2  0x25 - approach1_lane1  \\\n",
       "0   60                    0.00              16.152381               43.088000   \n",
       "1  120                    0.00              10.789286               35.253818   \n",
       "2  180                    0.00               9.412539               26.540897   \n",
       "3  240                    0.00               9.131486               19.972120   \n",
       "4  300                   77.76               8.904618               17.397326   \n",
       "\n",
       "   0x19 - approach3_lane3  0x32 - approach0_lane3  0x2 - approach0_lane2  \\\n",
       "0               77.126400               74.284000              35.702929   \n",
       "1               77.992989               73.467692              33.463262   \n",
       "2               80.211456               73.941677              20.850735   \n",
       "3               82.102297               74.745391              21.917401   \n",
       "4               81.800727               74.284000              21.914320   \n",
       "\n",
       "   0x28 - approach1_lane3  0x17 - exit0_lane1  0x1d - approach2_lane1  ...  \\\n",
       "0                  0.0000          103.680000               32.064000  ...   \n",
       "1                  0.0000           63.803077               21.495419  ...   \n",
       "2                  0.0000           57.202759                7.767860  ...   \n",
       "3                  0.0000           55.296000                4.773797  ...   \n",
       "4                 76.9248           56.233220                3.855391  ...   \n",
       "\n",
       "   0x15 - exit1_lane1  0x10 - exit3_lane3  0x12 - exit2_lane3  \\\n",
       "0           62.208000          102.060000           77.760000   \n",
       "1           56.552727          104.976000           74.225455   \n",
       "2           54.308571           99.977143           78.624000   \n",
       "3           53.512258          104.976000           78.783158   \n",
       "4           53.104390           93.312000           79.380000   \n",
       "\n",
       "   0x13 - exit2_lane1  0x14 - exit1_lane3  0x2e - approach0_lane1  \\\n",
       "0           82.080000          107.424000               53.979429   \n",
       "1           82.080000           94.785882               53.136000   \n",
       "2           62.767059           92.775273               48.032542   \n",
       "3           62.380800           96.681600               36.714753   \n",
       "4           54.720000           93.651692               29.220864   \n",
       "\n",
       "   0x18 - approach3_lane3  0xc - approach2_lane2  0xb - exit2_lane2  \\\n",
       "0               77.558400              10.990057          55.542857   \n",
       "1               86.176000               6.420397          55.741935   \n",
       "2               89.490462               6.018364          56.492308   \n",
       "3               89.490462               6.017104          54.443836   \n",
       "4               89.490462               5.919330          55.148936   \n",
       "\n",
       "   0x2a - approach1_lane3  \n",
       "0               75.048585  \n",
       "1               75.416471  \n",
       "2               75.663738  \n",
       "3               75.841352  \n",
       "4               72.766703  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out some of the rows\n",
    "\n",
    "delay_rows = [\"{} Delay\".format(d) for d in range(60,601,60)]\n",
    "delay_rename = dict([\n",
    "    (\"{} Delay\".format(d), d)\n",
    "    for d in range(60,601,60)\n",
    "])\n",
    "\n",
    "thru_rows = [\"{} Throughput\".format(d) for d in range(60,601,60)]\n",
    "thru_rename = dict([\n",
    "    (\"{} Throughput\".format(d), d)\n",
    "    for d in range(60,601,60)\n",
    "])\n",
    "\n",
    "vol_rows = [d for d in range(60,601,60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 approach zones, 12 exit zones\n"
     ]
    }
   ],
   "source": [
    "# Filter out some of the columns\n",
    "\n",
    "survey_zones = df_tmp.columns.values[1:]\n",
    "\n",
    "entrances = [x for x in survey_zones if 'approach' in x]\n",
    "exits = [y for y in survey_zones if 'exit' in y]\n",
    "\n",
    "print(\"{} approach zones, {} exit zones\".format(len(entrances), len(exits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_approach = re.compile('0x(\\w+) - approach.*')\n",
    "reg_exit = re.compile('0x(\\w+) - exit.*')\n",
    "\n",
    "entrances_rename = dict([\n",
    "    (k, SURVEY_ZONE_MAPPING[reg_approach.match(k).group(1)])\n",
    "    for k in entrances\n",
    "])\n",
    "\n",
    "exits_rename = dict([\n",
    "    (k, SURVEY_ZONE_MAPPING[reg_exit.match(k).group(1)])\n",
    "    for k in exits\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/localsim/.virtualenvs/thesis/local/lib/python2.7/site-packages/pandas/core/generic.py:6586: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/localsim/.virtualenvs/thesis/lib/python2.7/site-packages/ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "total_thru_dfs = []\n",
    "total_delay_dfs = []\n",
    "ave_delay_dfs = []\n",
    "ave_speed_dfs = []\n",
    "ave_travel_time_dfs = []\n",
    "\n",
    "for demand in _demands:\n",
    "    for weights in _weights:\n",
    "\n",
    "        partial_fn = 'old' if weights == (0, 0, 0) else 'a{}_b{}_c{}'.format(*weights)\n",
    "        filename = currdir + '/{}sim-results/result_d{}_{}.xls'.format(DF_PATH, demand, partial_fn)\n",
    "\n",
    "        # Get volumes\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='Volume').fillna(0)\n",
    "\n",
    "        df_tmp1 = df_tmp[df_tmp.t.isin(vol_rows)]\n",
    "        df_tmp1 = df_tmp1.sort_values(by='t').set_index('t')[entrances].stack().reset_index()\n",
    "        df_tmp1['level_1'] = df_tmp1['level_1'].map(entrances_rename)\n",
    "        df_tmp1 = df_tmp1.groupby(['t', 'level_1']).sum().reset_index()\n",
    "\n",
    "        df_volume = df_tmp1.pivot(index='t', columns='level_1', values=0)\n",
    "        df_volume.to_pickle(currdir + '/{}actual-volume/vol_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "        \n",
    "        # Get CVCC\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='CVCC').fillna(0).set_index('t')\n",
    "\n",
    "        df_cvcc = df_tmp.rename(columns=entrances_rename).rename(columns=exits_rename)\n",
    "        df_cvcc = df_cvcc.stack().reset_index().pivot_table(index='t', columns='level_1', values=0, aggfunc='sum')\n",
    "        \n",
    "        df_cvcc.to_pickle(currdir + '/{}cvcc/cvcc_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "        \n",
    "        # Get Travel Time\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='Travel time (s)')\n",
    "\n",
    "        df_tmp['approach'] = df_tmp.apply(lambda row: ROUTE_MAPPING[row['Route']][0], axis=1)\n",
    "        df_tmp['movement'] = df_tmp.apply(lambda row: ROUTE_MAPPING[row['Route']][1], axis=1)\n",
    "        df_tmp = df_tmp[['Average time', 'approach', 'movement']].rename(columns=_col_rename)\n",
    "        df_tmp['demand'] = [demand] * df_tmp.shape[0]\n",
    "        df_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_tmp['alpha'] = weights[0]\n",
    "        df_tmp['beta'] = weights[1]\n",
    "        df_tmp['gamma'] = weights[2]\n",
    "        df_tmp['model_type'] = _model_type[weights]\n",
    "        ave_travel_time_dfs.append(df_tmp)\n",
    "        \n",
    "        # Get Average Speed\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='Travel speed (kph)')\n",
    "\n",
    "        df_tmp['approach'] = df_tmp.apply(lambda row: ROUTE_MAPPING[row['Route']][0], axis=1)\n",
    "        df_tmp['movement'] = df_tmp.apply(lambda row: ROUTE_MAPPING[row['Route']][1], axis=1)\n",
    "        df_tmp = df_tmp[['Average speed', 'approach', 'movement']].rename(columns=_col_rename)\n",
    "        df_tmp['demand'] = [demand] * df_tmp.shape[0]\n",
    "        df_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_tmp['alpha'] = weights[0]\n",
    "        df_tmp['beta'] = weights[1]\n",
    "        df_tmp['gamma'] = weights[2]\n",
    "        df_tmp['model_type'] = _model_type[weights]\n",
    "        ave_speed_dfs.append(df_tmp)\n",
    "\n",
    "        # Get the cumulative delays\n",
    "        df_tmp = pd.read_excel(filename, sheet_name='Speed').fillna(0)\n",
    "\n",
    "        df_tmp1 = df_tmp[df_tmp.t.isin(delay_rows)]\n",
    "        df_tmp1['t'].replace(delay_rename, inplace=True)\n",
    "        df_tmp1 = df_tmp1.sort_values(by='t').set_index('t')[entrances].stack().reset_index()\n",
    "        df_tmp1['level_1'] = df_tmp1['level_1'].map(entrances_rename)\n",
    "        df_tmp1 = df_tmp1.groupby(['t', 'level_1']).sum().reset_index()\n",
    "\n",
    "        df_cumdelay = df_tmp1.pivot(index='t', columns='level_1', values=0)\n",
    "        df_cumdelay.to_pickle(currdir + '/{}cumu-delay/delay_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "        \n",
    "        # Get the cumulative throughputs\n",
    "\n",
    "        df_tmp3 = df_tmp[df_tmp.t.isin(thru_rows)]\n",
    "        for col in ['0x11 - exit3_lane1', '0x15 - exit1_lane1', '0x17 - exit0_lane1', '0x13 - exit2_lane1', '0x5 - exit0_lane2']:\n",
    "            if col not in df_tmp3.columns:\n",
    "                df_tmp3[col] = 0\n",
    "        df_tmp3['t'].replace(thru_rename, inplace=True)\n",
    "        df_tmp3 = df_tmp3.sort_values(by='t').set_index('t')[exits].stack().reset_index()\n",
    "        df_tmp3['level_1'] = df_tmp3['level_1'].map(exits_rename)\n",
    "        df_tmp3 = df_tmp3.groupby(['t', 'level_1']).sum().reset_index()\n",
    "\n",
    "        df_cumthru = df_tmp3.pivot(index='t', columns='level_1', values=0)\n",
    "        df_cumthru.to_pickle(currdir + '/{}cumu-thru/thru_d{}_a{}_b{}_c{}.pkl'.format(DF_PATH, demand, *weights))\n",
    "\n",
    "        # Get aggregate values\n",
    "\n",
    "        df_total_thru_tmp = df_cumthru.loc[600, :].reset_index().set_index('level_1').T\n",
    "        df_total_thru_tmp['demand'] = [demand]\n",
    "        df_total_thru_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_total_thru_tmp['alpha'] = weights[0]\n",
    "        df_total_thru_tmp['beta'] = weights[1]\n",
    "        df_total_thru_tmp['gamma'] = weights[2]\n",
    "        df_total_thru_tmp['model_type'] = _model_type[weights]\n",
    "        total_thru_dfs.append(df_total_thru_tmp)\n",
    "\n",
    "        df_total_delay_tmp = df_cumdelay.loc[600, :].reset_index().set_index('level_1').T\n",
    "        df_total_delay_tmp['demand'] = [demand]\n",
    "        df_total_delay_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_total_delay_tmp['alpha'] = weights[0]\n",
    "        df_total_delay_tmp['beta'] = weights[1]\n",
    "        df_total_delay_tmp['gamma'] = weights[2]\n",
    "        df_total_delay_tmp['model_type'] = _model_type[weights]\n",
    "        total_delay_dfs.append(df_total_delay_tmp)\n",
    "\n",
    "        df_tmp2 = df_tmp[df_tmp.t == 'Average Delay'][entrances].rename(columns=entrances_rename).stack().reset_index()\n",
    "        df_ave_delay_tmp = df_tmp2.groupby('level_1').mean().reset_index().pivot(index='level_0', columns='level_1', values=0)\n",
    "        df_ave_delay_tmp['demand'] = [demand]\n",
    "        df_ave_delay_tmp['new_model'] = weights != (0, 0, 0)\n",
    "        df_ave_delay_tmp['alpha'] = weights[0]\n",
    "        df_ave_delay_tmp['beta'] = weights[1]\n",
    "        df_ave_delay_tmp['gamma'] = weights[2]\n",
    "        df_ave_delay_tmp['model_type'] = _model_type[weights]\n",
    "        ave_delay_dfs.append(df_ave_delay_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_thru = pd.concat(total_thru_dfs).reset_index().iloc[:, 1:]\n",
    "df_total_thru.to_pickle(currdir + '/{}total_throughput.pkl'.format(DF_PATH))\n",
    "\n",
    "df_total_delay = pd.concat(total_delay_dfs).reset_index().iloc[:, 1:]\n",
    "df_total_delay.to_pickle(currdir + '/{}total_delay.pkl'.format(DF_PATH))\n",
    "\n",
    "df_ave_delay = pd.concat(ave_delay_dfs).reset_index().iloc[:, 1:]\n",
    "df_ave_delay.to_pickle(currdir + '/{}ave_delay.pkl'.format(DF_PATH))\n",
    "\n",
    "df_ave_speed = pd.concat(ave_speed_dfs).reset_index().iloc[:, 1:]\n",
    "df_ave_speed.to_pickle(currdir + '/{}ave_speed.pkl'.format(DF_PATH))\n",
    "\n",
    "df_travel_time = pd.concat(ave_travel_time_dfs).reset_index().iloc[:, 1:]\n",
    "df_travel_time.to_pickle(currdir + '/{}ave_travel_time.pkl'.format(DF_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greentimes from Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing greentimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_greentime_map(dfg, title=\"Greentime maps\", headless=False, filename='greentime.png', movements=True):\n",
    "    fig, axs = plt.subplots(figsize=(10,5))\n",
    "\n",
    "    dfg_matrix = dfg.T\n",
    "    if movements:\n",
    "        dfg_matrix = dfg_matrix.reindex(index=[\n",
    "            (2,LEFT_TURN,NORTHBOUND), (2,RIGHT_TURN,NORTHBOUND), (2,THROUGH_TURN,NORTHBOUND),\n",
    "            (2,LEFT_TURN,SOUTHBOUND), (2,RIGHT_TURN,SOUTHBOUND), (2,THROUGH_TURN,SOUTHBOUND),\n",
    "            (2,LEFT_TURN,EASTBOUND), (2,RIGHT_TURN,EASTBOUND), (2,THROUGH_TURN,EASTBOUND),\n",
    "            (2,LEFT_TURN,WESTBOUND), (2,RIGHT_TURN,WESTBOUND), (2,THROUGH_TURN,WESTBOUND),\n",
    "        ]).rename(index=_movement_labels).rename_axis(index='Movements', columns='Timesteps')\n",
    "    sns.heatmap(data=dfg_matrix, cbar=False)\n",
    "    \n",
    "    fig.suptitle(title, fontsize=18)\n",
    "    \n",
    "    if headless:\n",
    "        fig.savefig(IMAGE_PATH + filename)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, filename):\n",
    "    df.to_pickle(DF_PATH + filename + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _demands = [\n",
    "#     450,\n",
    "#     900,\n",
    "#     (450, 900),\n",
    "#     (900, 1800)\n",
    "# ]\n",
    "\n",
    "# _weights = [\n",
    "#     (1, 0, 0),\n",
    "#     (0, 1, 0),\n",
    "#     (0, 0, 1),\n",
    "#     (0.5, 0.5, 0),\n",
    "#     (0, 0.5, 0.5),\n",
    "#     (0.5, 0, 0.5),\n",
    "#     (0.33, 0.33, 0.33),\n",
    "#     (0, 0, 0)\n",
    "# ]\n",
    "\n",
    "# for demand in _demands:\n",
    "#     for weights in _weights:\n",
    "#         if weights == (0,0,0):\n",
    "#             df_e0 = pd.read_pickle(DF_PATH + 'greentimes/initial/greentimes_d{}_old.pkl'.format(demand))\n",
    "#             df_e1 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch1_old.pkl'.format(demand))\n",
    "#             df_e2 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch2_old.pkl'.format(demand))\n",
    "#             df_e3 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch3_old.pkl'.format(demand))\n",
    "#             subtitle = 'Old model'\n",
    "#             filename = 'old'\n",
    "#         else:\n",
    "#             df_e0 = pd.read_pickle(DF_PATH + 'greentimes/initial/greentimes_d{}_new_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "#             df_e1 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch1_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "#             df_e2 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch2_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "#             df_e3 = pd.read_pickle(DF_PATH + 'greentimes/greentimes_d{}_epoch3_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "#             subtitle = 'New model ({})'.format(_model_type[weights])\n",
    "#             filename = 'a{}_b{}_c{}'.format(*weights)\n",
    "            \n",
    "#         plot_greentime_map(\n",
    "#             df_e0,\n",
    "#             title='Greentimes for demand {} and {} (Initial)'.format(demand, subtitle),\n",
    "#             headless=True,\n",
    "#             filename='d{}_{}_epoch0.png'.format(demand, filename)\n",
    "#         )\n",
    "\n",
    "#         plot_greentime_map(\n",
    "#             df_e1,\n",
    "#             title='Greentimes for demand {} and {} (Epoch 1)'.format(demand, subtitle),\n",
    "#             headless=True,\n",
    "#             filename='d{}_{}_epoch1.png'.format(demand, filename)\n",
    "#         )\n",
    "        \n",
    "#         plot_greentime_map(\n",
    "#             df_e2,\n",
    "#             title='Greentimes for demand {} and {} (Epoch 2)'.format(demand, subtitle),\n",
    "#             headless=True,\n",
    "#             filename='d{}_{}_epoch2.png'.format(demand, filename)\n",
    "#         )\n",
    "        \n",
    "#         plot_greentime_map(\n",
    "#             df_e3,\n",
    "#             title='Greentimes for demand {} and {} (Epoch 3)'.format(demand, subtitle),\n",
    "#             headless=True,\n",
    "#             filename='d{}_{}_epoch3.png'.format(demand, filename)\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results from MILP Realtime Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining across epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results_dflist = []\n",
    "\n",
    "for demand in _demands:\n",
    "    for weights in _weights:\n",
    "        if weights == (0,0,0):\n",
    "            df_e1 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch1_old.csv'.format(demand))\n",
    "            df_e2 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch2_old.csv'.format(demand))\n",
    "            df_e3 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch3_old.csv'.format(demand))\n",
    "        else:\n",
    "            df_e1 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch1_a{}_b{}_c{}.csv'.format(demand, *weights))\n",
    "            df_e2 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch2_a{}_b{}_c{}.csv'.format(demand, *weights))\n",
    "            df_e3 = pd.read_csv(DF_PATH + 'milp-results/results_d{}_epoch3_a{}_b{}_c{}.csv'.format(demand, *weights))\n",
    "\n",
    "        df_e1 = df_e1.rename(columns=_col_rename)\n",
    "        df_e1['demand'] = [demand]\n",
    "        df_e1['new_model'] = weights != (0,0,0)\n",
    "        df_e1['alpha'] = weights[0]\n",
    "        df_e1['beta'] = weights[1]\n",
    "        df_e1['gamma'] = weights[2]\n",
    "        df_e1['model_type'] = _model_type[weights]\n",
    "        df_e1['epoch'] = 1\n",
    "        \n",
    "        df_e2 = df_e2.rename(columns=_col_rename)\n",
    "        df_e2['demand'] = [demand]\n",
    "        df_e2['new_model'] = weights != (0,0,0)\n",
    "        df_e2['alpha'] = weights[0]\n",
    "        df_e2['beta'] = weights[1]\n",
    "        df_e2['gamma'] = weights[2]\n",
    "        df_e2['model_type'] = _model_type[weights]\n",
    "        df_e2['epoch'] = 2\n",
    "        \n",
    "        df_e3 = df_e3.rename(columns=_col_rename)\n",
    "        df_e3['demand'] = [demand]\n",
    "        df_e3['new_model'] = weights != (0,0,0)\n",
    "        df_e3['alpha'] = weights[0]\n",
    "        df_e3['beta'] = weights[1]\n",
    "        df_e3['gamma'] = weights[2]\n",
    "        df_e3['model_type'] = _model_type[weights]\n",
    "        df_e3['epoch'] = 3\n",
    "        \n",
    "        _results_dflist.append(pd.concat([df_e1, df_e2, df_e3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(_results_dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_results = pd.read_pickle(DF_PATH + 'results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_results['demand'] = df_initial_results.apply(lambda row: \n",
    "                                                        int(row['demand_ns']) if row['demand_ns'] == row['demand_ew']\n",
    "                                                        else (int(row['demand_ns']), int(row['demand_ew']))\n",
    "                                                        , axis=1)\n",
    "\n",
    "df_initial_results['new_model'] = df_initial_results.apply(lambda row: row['alpha'] != 0, axis=1)\n",
    "\n",
    "df_initial_results['model_type'] = df_initial_results.apply(lambda row: _model_type[\n",
    "    (row['alpha'], row['beta'], row['gamma'])\n",
    "], axis=1)\n",
    "\n",
    "df_initial_results['epoch'] = 0\n",
    "\n",
    "df_initial_results['delay'] = df_initial_results['delay'].apply(lambda x: 2*x)\n",
    "\n",
    "df_initial_results = df_initial_results[[\n",
    "    'runtime',\n",
    "    'delay',\n",
    "    'throughput',\n",
    "    'objective_value',\n",
    "    'demand',\n",
    "    'new_model',\n",
    "    'alpha',\n",
    "    'beta',\n",
    "    'gamma',\n",
    "    'model_type',\n",
    "    'epoch'\n",
    "]]\n",
    "\n",
    "df = df.rename(columns={'obj-value': 'objective_value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_initial_results, df]).sort_values(by=['epoch', 'demand', 'model_type'])\n",
    "\n",
    "save_df(df_final, 'milp-realtime-results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected vs Actual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_dfs = []\n",
    "throughput_dfs = []\n",
    "\n",
    "df_milp = pd.read_pickle(DF_PATH + 'milp-realtime-results.pkl')\n",
    "df_delay = pd.DataFrame(columns=['demand', 'model_type', 'expected', 'actual', 'epoch'])\n",
    "df_thru = pd.DataFrame(columns=['demand', 'model_type', 'expected', 'actual', 'epoch'])\n",
    "\n",
    "for demand in _demands:\n",
    "    for weights in _weights:\n",
    "\n",
    "        # Get actual values\n",
    "        \n",
    "        df_cumdelay_tmp = pd.read_pickle(DF_PATH + 'cumu-delay/delay_d{}_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "        df_instdelay_tmp = df_cumdelay_tmp.diff()\n",
    "        df_instdelay_tmp.loc[60, :] = df_cumdelay_tmp.loc[60, :]\n",
    "        actual_delay = list(df_instdelay_tmp.sum(axis=1)[[60, 240, 420]])\n",
    "        \n",
    "        df_cumthru_tmp = pd.read_pickle(DF_PATH + 'cumu-thru/thru_d{}_a{}_b{}_c{}.pkl'.format(demand, *weights))\n",
    "        df_instthru_tmp = df_cumthru_tmp.diff()\n",
    "        df_instthru_tmp.loc[60, :] = df_cumthru_tmp.loc[60, :]\n",
    "        actual_thru = list(df_instthru_tmp.sum(axis=1)[[60, 240, 420]])\n",
    "\n",
    "        # Get expected values\n",
    "        \n",
    "        expected_delay = list(df_milp[(df_milp.demand == demand) & (df_milp.model_type == _model_type[weights])].delay)\n",
    "        expected_thru = list(df_milp[(df_milp.demand == demand) & (df_milp.model_type == _model_type[weights])].throughput)\n",
    "        \n",
    "        # Combine into a dataframe\n",
    "        \n",
    "        for i in range(3):\n",
    "            df_delay.loc[-1] = [demand, _model_type[weights], expected_delay[i], actual_delay[i], i]\n",
    "            df_thru.loc[-1] = [demand, _model_type[weights], expected_thru[i], actual_thru[i], i]\n",
    "            df_delay.index += 1\n",
    "            df_thru.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.to_pickle(DF_PATH + \"delay_comparison.pkl\")\n",
    "df_thru.to_pickle(DF_PATH + \"throughput_comparison.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
